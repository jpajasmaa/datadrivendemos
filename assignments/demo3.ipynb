{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357964b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbe4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c850693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from desdeo_emo.EAs import RVEA, NSGAIII\n",
    "from desdeo_problem.testproblems.TestProblems import test_problem_builder\n",
    "from desdeo_problem import DataProblem\n",
    "from desdeo_tools.utilities import fast_non_dominated_sort, hypervolume_indicator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from pyDOE import lhs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aef005",
   "metadata": {},
   "source": [
    "## Assignment 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f09ff5",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    " Use EI and the mean prediction to solve any single objective benchmark problem (e.g.\n",
    "Ackley, Rosenblock, sphere etc.) with any single objective optimizer (preferably GA). \n",
    "\n",
    "Set max exact function evaluations to 50 (start with 50 design points). Was the solutions\n",
    "found by EI better? (you can implement EI is you wish to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dc5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem is the expensive function to evaluate.\n",
    "# use ackley\n",
    "\n",
    "\n",
    "# prob takes now all as vectors, need to change GA to do so too.\n",
    "def problem(x):\n",
    "    # if only one solution to calculate\n",
    "    if x.shape[0] == 2:\n",
    "        term1 = -20 * np.exp(-0.2 * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))\n",
    "        term2 = np.exp(0.5 * (np.cos(2 * np.pi * x[0]) + np.cos(2 * np.pi * x[1])))\n",
    "    else:\n",
    "        term1 = -20 * np.exp(-0.2 * np.sqrt(0.5 * (x[:,0]**2 + x[:,1]**2)))\n",
    "        term2 = np.exp(0.5 * (np.cos(2 * np.pi * x[:,0]) + np.cos(2 * np.pi * x[:,1])))\n",
    "    return term1 - term2 + np.exp(1) + 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dedc61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, WhiteKernel, RationalQuadratic, DotProduct, ConstantKernel, Matern\n",
    "\n",
    "class real_GA:\n",
    "    def __init__(self, problem, pop, pop_size, pm, bounds, di, order, fitness=None, acf=False, use_surr=False, max_func_evals=50, gen_max=50):\n",
    "        self.problem = problem # problem function to solve\n",
    "        self.pop = pop # pop array to hold binary population strings\n",
    "        self.pm = pm # probability of mutation\n",
    "        self.pop_size = pop_size # population size\n",
    "        self.lbounds = bounds[0]\n",
    "        self.ubounds = bounds[1]\n",
    "        self.di = di # for crossover\n",
    "        self.order = order # for mutation\n",
    "        self.acf = acf\n",
    "        self.use_surr = use_surr\n",
    "        self.gen_max = gen_max # max generations\n",
    "        self.max_func_evals = max_func_evals\n",
    "        \n",
    "        self.fitness = fitness # fitness array to hold calculated fitness values\n",
    "        self.gen = 0 # current generation\n",
    "        self.surr = None\n",
    "        \n",
    "    # start pop and evaluate each member in the pop\n",
    "    def initialize(self):\n",
    "        if len(self.pop) < 1:\n",
    "            x1range = np.random.uniform(low=self.lbounds[0], high=self.ubounds[0], size=self.pop_size)\n",
    "            x2range = np.random.uniform(low=self.lbounds[1], high=self.ubounds[1], size=self.pop_size)\n",
    "            self.pop = np.stack((x1range, x2range), axis=-1)\n",
    "\n",
    "        self.pop_size = self.pop.shape[0]\n",
    "\n",
    "\n",
    "    # run the GA for one iteration\n",
    "    def run(self):\n",
    "        n = 0 # init iterations\n",
    "        self.initialize()\n",
    "\n",
    "        next_gen = [] # init next_gen population array\n",
    "        for i in range(int(self.pop.shape[0]/2)):\n",
    "            # select two individuals with deterministic tournament selection, append them in a next gen list for crossover\n",
    "            i1, i2 = self.tour_select()\n",
    "            s1 = self.pop[i1]\n",
    "            s2 = self.pop[i2]\n",
    "            next_gen.append(s1)\n",
    "            next_gen.append(s2)\n",
    "            \n",
    "        # crossover. Happens every time\n",
    "        next_gen = self.SBX(next_gen)\n",
    "            \n",
    "        # Mutation. happens if rand < pm for member in pop\n",
    "        for i in range(self.pop_size):\n",
    "            if np.random.rand() < self.pm:\n",
    "                next_gen[i] = self.poly_mutation(next_gen[i], self.order)\n",
    "         \n",
    "        self.pop = np.asarray(next_gen) # add next gen to self pop               \n",
    "        n += 1\n",
    "        self.gen += 1       \n",
    " \n",
    "    \n",
    "    # evaluate population members\n",
    "    def evaluate(self, x):\n",
    "        return problem(x)\n",
    "        \n",
    "        \n",
    "    # deterministic binary tournament selection\n",
    "    def tour_select(self):        \n",
    "        cf = self.fitness\n",
    "        b1 = np.argmin(cf) # get best member by fitness\n",
    "        cf = np.delete(cf, b1) # remove it from cf\n",
    "        b2 = np.argmin(cf) # get (2nd) best member by fitness\n",
    "        return b1, b2 # return best and 2nd best members as parents\n",
    "        \n",
    "        \n",
    "    # Simulated binary crossover (non-bounded)\n",
    "    def SBX(self, parents):\n",
    "        parents = np.asarray(parents)\n",
    "        pop_size, num_var = parents.shape\n",
    "        children = np.zeros_like(parents)\n",
    "        for i in range(0, pop_size, num_var):\n",
    "            p1 = (parents[i] + parents[i + 1]) / 2\n",
    "            p2 = (parents[i] - parents[i + 1]) / 2\n",
    "            beta = np.zeros(num_var)\n",
    "            alpha = np.random.rand(num_var)\n",
    "            bx = np.random.randint(0, high=2, size=num_var)\n",
    "            beta[alpha <= 0.5] = (2 * alpha[alpha <= 0.5])**(1 / (self.di + 1))\n",
    "            beta[alpha > 0.5] = (2 - 2 * alpha[alpha > 0.5])**(-1 / (self.di + 1))            \n",
    "            beta = beta * ((-1)**bx)\n",
    "            children[i] = p1 + beta * p2\n",
    "            children[i + 1] = p1 - beta * p2\n",
    "        return children\n",
    "        \n",
    "    \n",
    "    # polynomial mutation for one pop member p\n",
    "    def poly_mutation(self, p, order):\n",
    "        children = np.array([0,0])\n",
    "        for i in range(0, 2):\n",
    "            pL = self.lbounds[i]\n",
    "            pU = self.ubounds[i]\n",
    "            u = np.random.random() # r [0,1]\n",
    "            mp = 0\n",
    "            dl = (2*u)**(1/1+order) - 1\n",
    "            dr = 1 - (2*(1 - u))**(1/1+order) \n",
    "            if u <= 0.5:\n",
    "                mp = p[i] + dl*(p[i] - pL)\n",
    "            else:\n",
    "                mp = p[i] + dr*(pU - p[i])\n",
    "            children[i] = mp\n",
    "        return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84eb57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(dec_dim, samples, bounds):\n",
    "    # create samples \n",
    "    x = lhs(dec_dim, samples)    \n",
    "    # scale\n",
    "    #lower = bounds[0]\n",
    "    #upper = bounds[1]\n",
    "    #x = x * (upper - lower) + lower    \n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6919050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "pop_s = 50\n",
    "pm = 0.1\n",
    "bounds = np.array([[-2, -2], [2, 2]]) # variable bounds (lower, upper)\n",
    "gen_max = 50\n",
    "use_surr = True\n",
    "fmax = 50 # max func evals\n",
    "di = 2 # distribution index\n",
    "order = 20 # polynomial order param\n",
    "acf = True\n",
    "\n",
    "times = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf80f62",
   "metadata": {},
   "source": [
    "### Using mean pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b62ae39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "best surrogate fitness 0.3160056220939964\n",
      "best decision values [ 0.88550555 -3.05202942]\n",
      "best surr func value 4.510883626838375\n",
      "==============================\n",
      "best y 0.31600562157358425\n",
      "best x [0.06627558 0.01841257]\n",
      "==============================\n",
      "best surrogate fitness 0.8017083811979191\n",
      "best decision values [1.74925339 1.01302451]\n",
      "best surr func value 1.0432063282607231\n",
      "==============================\n",
      "best y 0.8017083816547519\n",
      "best x [-0.09276491  0.09614741]\n",
      "==============================\n",
      "best surrogate fitness 0.9020644091565941\n",
      "best decision values [1.02649893 0.13814612]\n",
      "best surr func value 2.637531092108304\n",
      "==============================\n",
      "best y 0.9020644063077974\n",
      "best x [0.00244123 0.14710911]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "def surrogate(model, x):\n",
    "    return model.predict(x, return_std=True)\n",
    "\n",
    "def posteori_mean_pred(x, model):\n",
    "    # x = np.vstack((x, x_samples))\n",
    "    return model.predict(x)\n",
    "    \n",
    "# .. but this is still done by creating new samples eg. random search..\n",
    "def opt_acq(x, y, model):\n",
    "    x_samples = create_samples(2, 50, bounds)\n",
    "    \n",
    "    scores = posteori_mean_pred(x_, model)\n",
    "    #ix = np.argmin(scores)\n",
    "    best_x = np.argmin(scores)\n",
    "    \n",
    "    sampled_scores = posteori_mean_pred(x_samples, model)\n",
    "    best_sampled = np.argmin(sampled_scores)\n",
    "    \n",
    "    if x[best_x] < x_samples[best_sampled]:\n",
    "        return best_x\n",
    "    else:\n",
    "        return best_sampled\n",
    "\n",
    "mean_pred_result_all = []\n",
    "\n",
    "for _ in range(3):\n",
    "       \n",
    "    x = create_samples(2, pop_s, bounds)\n",
    "    pop = x\n",
    "    y = problem(x)\n",
    "    kernel = 1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n",
    "    model = GaussianProcessRegressor(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y)\n",
    "    ga = real_GA(problem, pop, pop_s, pm, bounds, di, order, y, acf, use_surr, fmax, gen_max) \n",
    "    \n",
    "    fmax = 0           \n",
    "    while fmax < 50:\n",
    "        best_x = np.argmin(posteori_mean_pred(x, model))\n",
    "        best_x = ga.pop[best_x]\n",
    "        \n",
    "        true_y = problem(best_x) # + 1 fmax..\n",
    "        fmax += 1\n",
    "        \n",
    "        # add to data. have to keep x, y == pop.size to not break GA currently.\n",
    "        worst_y = np.argmax(y)\n",
    "        x = np.delete(x, worst_y, axis=0)\n",
    "        y = np.delete(y, worst_y, axis=0)\n",
    "    \n",
    "        x = np.vstack((x, [best_x]))\n",
    "        y = np.hstack((y, [true_y]))\n",
    "    \n",
    "        # update surr\n",
    "        #model.fit(x, y)\n",
    "        \n",
    "        # no idea if this is making sense.\n",
    "        # run GA for iteration\n",
    "        ga.pop = x\n",
    "        ga.fitness = y  \n",
    "        for _ in range(5):    \n",
    "            ga.run()\n",
    "            ga.fitness = model.predict(x)\n",
    "            \n",
    "        #x = ga.pop\n",
    "        #y = ga.fitness\n",
    "        \n",
    "        # update surr\n",
    "        model.fit(x, y)\n",
    "            \n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    fittest = ga.fitness[fittest_idx]\n",
    "    print(\"==============================\")\n",
    "    print(\"best surrogate fitness\", fittest)\n",
    "    print(\"best decision values\", ga.pop[fittest_idx])\n",
    "    print(\"best surr func value\", true_y)\n",
    "  \n",
    "    print(\"==============================\")\n",
    "    fit = np.min(y)\n",
    "    print(\"best y\", fit)\n",
    "    print(\"best x\", x[np.argmin(y)])\n",
    "\n",
    "    mean_pred_result_all.append(fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f3f04d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.057912951795295"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem(np.array([0.06012606, 0.15288274]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9686bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31600562157358425, 0.8017083816547519, 0.9020644063077974]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pred_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf0bd7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6732594698453779"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_pred_result_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df40e9",
   "metadata": {},
   "source": [
    "### using EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ede7dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "best surrogate fitness 0.1610240491836521\n",
      "best decision values [1.48331427 3.05476688]\n",
      "best func value 9.371877767828888\n",
      "==============================\n",
      "best y 0.16102404667708825\n",
      "best x [ 0.04111381 -0.00239903]\n",
      "==============================\n",
      "best surrogate fitness 0.1274652327433614\n",
      "best decision values [ 0.00969454 -0.04199655]\n",
      "best func value 0.17065227285930362\n",
      "==============================\n",
      "best y 0.12746522860456722\n",
      "best x [ 0.00968752 -0.03276969]\n",
      "==============================\n",
      "best surrogate fitness 0.2779881953125596\n",
      "best decision values [-0.12590243  0.00474385]\n",
      "best func value 0.7287449756483539\n",
      "==============================\n",
      "best y 0.27798819082421033\n",
      "best x [ 0.05725965 -0.02510508]\n",
      "==============================\n",
      "best surrogate fitness 0.29323762726068026\n",
      "best decision values [-1.71842409  0.77888873]\n",
      "best func value 6.41032147795152\n",
      "==============================\n",
      "best y 0.293237622964444\n",
      "best x [-0.01942988  0.06210965]\n",
      "==============================\n",
      "best surrogate fitness 0.4809452797526319\n",
      "best decision values [0.11769887 0.31464209]\n",
      "best func value 2.4587300488594686\n",
      "==============================\n",
      "best y 0.4809452797999576\n",
      "best x [ 0.08985791 -0.02524024]\n",
      "==============================\n",
      "best surrogate fitness 0.04785725484268255\n",
      "best decision values [0.1407489  0.09885266]\n",
      "best func value 1.1372252641277463\n",
      "==============================\n",
      "best y 0.04785723327518454\n",
      "best x [-0.00192744 -0.01472257]\n",
      "==============================\n",
      "best surrogate fitness 1.1178322216239849\n",
      "best decision values [0.14274496 0.12934183]\n",
      "best func value 1.32908110918153\n",
      "==============================\n",
      "best y 1.0714920082285175\n",
      "best x [0.10131322 0.12964113]\n",
      "==============================\n",
      "best surrogate fitness 0.12336335522093123\n",
      "best decision values [-1.64056311  1.10522724]\n",
      "best func value 6.518453995034815\n",
      "==============================\n",
      "best y 0.1233633501207052\n",
      "best x [0.01419892 0.03009352]\n",
      "==============================\n",
      "best surrogate fitness 0.14784123670142435\n",
      "best decision values [0.03646397 0.00788982]\n",
      "best func value 0.1421767749433407\n",
      "==============================\n",
      "best y 0.14784122983049386\n",
      "best x [0.0368679  0.01103891]\n",
      "==============================\n",
      "best surrogate fitness 0.1268281669097604\n",
      "best decision values [-0.06286204  0.02378588]\n",
      "best func value 0.30639649736879804\n",
      "==============================\n",
      "best y 0.12682815593892727\n",
      "best x [0.01409151 0.03097537]\n",
      "==============================\n",
      "best surrogate fitness 0.06948038706468651\n",
      "best decision values [1. 1.]\n",
      "best func value 3.6253849384403622\n",
      "==============================\n",
      "best y 0.06948036303601057\n",
      "best x [0.02026552 0.00363019]\n",
      "==============================\n",
      "best surrogate fitness 0.4150264370550758\n",
      "best decision values [0.13747937 0.07100354]\n",
      "best func value 0.9787707136300945\n",
      "==============================\n",
      "best y 0.4150264339827956\n",
      "best x [0.04424393 0.07113347]\n",
      "==============================\n",
      "best surrogate fitness 0.00610573234689582\n",
      "best decision values [ 0.1075368  -0.00945875]\n",
      "best func value 0.5879685177693013\n",
      "==============================\n",
      "best y 0.006105703772497861\n",
      "best x [0.00178848 0.0011318 ]\n",
      "==============================\n",
      "best surrogate fitness 0.09519090029330357\n",
      "best decision values [0.01157528 0.00315616]\n",
      "best func value 0.03776383160536412\n",
      "==============================\n",
      "best y 0.09519088364699613\n",
      "best x [ 0.02041721 -0.01748891]\n",
      "==============================\n",
      "best surrogate fitness 0.10432404496239656\n",
      "best decision values [ 0.06871145 -0.07637916]\n",
      "best func value 0.5529574471361229\n",
      "==============================\n",
      "best y 0.10432404178051158\n",
      "best x [0.01204815 0.02638956]\n",
      "==============================\n",
      "best surrogate fitness 0.0912082528539031\n",
      "best decision values [0.19139142 0.0075655 ]\n",
      "best func value 1.28002411046036\n",
      "==============================\n",
      "best y 0.09120825040614733\n",
      "best x [0.00454354 0.02554335]\n",
      "==============================\n",
      "best surrogate fitness 0.2154869720187662\n",
      "best decision values [ 0.02554567 -0.04282646]\n",
      "best func value 0.20612416878181605\n",
      "==============================\n",
      "best y 0.21548692175062456\n",
      "best x [ 0.02838346 -0.04307494]\n",
      "==============================\n",
      "best surrogate fitness 0.06999890120720664\n",
      "best decision values [0.05906017 0.0112294 ]\n",
      "best func value 0.2635403720206817\n",
      "==============================\n",
      "best y 0.06999889797445036\n",
      "best x [0.01869546 0.00893145]\n",
      "==============================\n",
      "best surrogate fitness 0.15801924212679452\n",
      "best decision values [ 2.37312219 -1.39656459]\n",
      "best func value 8.6956026548781\n",
      "==============================\n",
      "best y 0.15801923385528838\n",
      "best x [ 0.01404579 -0.03805735]\n",
      "==============================\n",
      "best surrogate fitness 0.06833322393663366\n",
      "best decision values [1.25536262 0.30514072]\n",
      "best func value 5.228244143137118\n",
      "==============================\n",
      "best y 0.0683332222763191\n",
      "best x [ 0.01639591 -0.01195773]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "EI_result_all = []\n",
    "\n",
    "def surrogate(model, x):\n",
    "    return model.predict(x, return_std=True)\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.special import ndtr\n",
    "\n",
    "def EI(mean, std, max_val, tradeoff):\n",
    "    imp = (mean - max_val - tradeoff)\n",
    "    z = imp / std\n",
    "    ei = imp * norm.cdf(z) + std * norm.pdf(z)\n",
    "    ei[std == 0.0] = 0.0\n",
    "    return ei\n",
    "    \n",
    "\n",
    "def expected_impr(x0, x_sample, y, model):\n",
    "    mu, sigma = model.predict(x0, return_std=True)\n",
    "    sigma = sigma.reshape(-1, 1)\n",
    "    max_val = np.max(y)\n",
    "    tradeoff = 0.01\n",
    "\n",
    "    return EI(mu, sigma, max_val, tradeoff)\n",
    "\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def propose_location(X_sample, Y_sample, model, bounds, n_restarts=25):\n",
    "    dim = X_sample.shape[1]\n",
    "    min_val = 1\n",
    "    min_x = np.array([1.,1.]) # atleast return something\n",
    "    \n",
    "    def min_obj(X0):\n",
    "        # Minimization objective is the negative acquisition function\n",
    "        return expected_impr(X0.reshape(1, -1), X_sample, Y_sample, model)\n",
    "    \n",
    "    # Find the best optimum by starting from n_restart different random points.   \n",
    "    for x0 in np.random.uniform(-2, 2, size=(n_restarts, dim)):\n",
    "        res = minimize(min_obj, x0=x0, bounds=((-2.1,2.1),(-2.1, 2.1)), method='L-BFGS-B')\n",
    "        if res.fun < min_val:\n",
    "            min_val = res.fun\n",
    "            min_x = res.x                       \n",
    "    return min_x\n",
    "\n",
    "EI_result_all = []\n",
    "\n",
    "for _ in range(times):\n",
    "    x = create_samples(2, pop_s, bounds)\n",
    "    pop = x\n",
    "    y = problem(x)\n",
    "    kernel = 1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5)\n",
    "    \n",
    "    model = GaussianProcessRegressor(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y)\n",
    "    \n",
    "    ga = real_GA(problem, pop, pop_s, pm, bounds, di, order, y, acf, use_surr, fmax, gen_max) \n",
    "    \n",
    "    fmax = 0\n",
    "    while fmax < 50:\n",
    "\n",
    "        best_x = propose_location(x, y, model, bounds, n_restarts=25)\n",
    "        #print(best_x)\n",
    "        true_y = problem(best_x) # + 1 fmax..\n",
    "        fmax += 1\n",
    "        \n",
    "        # add to data. have to keep x, y == pop.size to not break GA currently.\n",
    "        worst_y = np.argmax(y)\n",
    "        x = np.delete(x, worst_y, axis=0)\n",
    "        y = np.delete(y, worst_y, axis=0)\n",
    "        x = np.vstack((x, best_x))\n",
    "        y = np.hstack((y, true_y))\n",
    "    \n",
    "        # update surr\n",
    "        #model.fit(x, y)\n",
    "        # TODO you really need x and y and copies for ga pops and not mix them atleast for the prints.\n",
    "        ga.pop = x\n",
    "        ga.fitness = y\n",
    "         \n",
    "        # no idea if this is making sense.\n",
    "        # run GA for iteration\n",
    "        for _ in range(5):\n",
    "         #   ga.pop = x\n",
    "            # run GA for one iteration  \n",
    "            ga.run()\n",
    "            # evaluate with surrogate\n",
    "            ga.fitness = model.predict(x)\n",
    "            \n",
    "        #x = ga.pop\n",
    "        #y = ga.fitness\n",
    "        # update surr\n",
    "        model.fit(x, y)\n",
    "\n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    fittest = ga.fitness[fittest_idx]\n",
    "    fit_ind = ga.pop[fittest_idx]\n",
    "    # eval fittest with true function for real result\n",
    "    true_val = problem(fit_ind)\n",
    "    print(\"==============================\")\n",
    "    print(\"best surrogate fitness\", fittest)\n",
    "    print(\"best decision values\", fit_ind)\n",
    "    print(\"best func value\", true_val)\n",
    "    \n",
    "    print(\"==============================\")\n",
    "    fit = np.min(y)\n",
    "    print(\"best y\", fit)\n",
    "    print(\"best x\", x[np.argmin(y)])\n",
    "\n",
    "    EI_result_all.append(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2d63959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16102404667708825,\n",
       " 0.12746522860456722,\n",
       " 0.27798819082421033,\n",
       " 0.293237622964444,\n",
       " 0.4809452797999576,\n",
       " 0.04785723327518454,\n",
       " 1.0714920082285175,\n",
       " 0.1233633501207052,\n",
       " 0.14784122983049386,\n",
       " 0.12682815593892727,\n",
       " 0.06948036303601057,\n",
       " 0.4150264339827956,\n",
       " 0.006105703772497861,\n",
       " 0.09519088364699613,\n",
       " 0.10432404178051158,\n",
       " 0.09120825040614733,\n",
       " 0.21548692175062456,\n",
       " 0.06999889797445036,\n",
       " 0.15801923385528838,\n",
       " 0.0683332222763191]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ac26476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20756081493728687"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(EI_result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "366c8730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5698942510031451"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem(np.array([-0.02398404,  0.10269]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef00784",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "koko GA taitaa nyt jäädä käyttämättä. Ilmeisesti sillä pitäisi optimoida tuota EI mutta kun ei osaa niin ei osaa. menköön scipy minimizellä sitten. posteriorissa sitä ei vissin edes tarvitse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b646ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce01bcf",
   "metadata": {},
   "source": [
    "#### Botorch stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a95d55",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Solve any benchmark problems (K=2 and 5, n=10) with ParEGO and LCB.\n",
    "Start with 109 design points. Compare the hypervolume of the solutions after 100 exact function\n",
    "evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d5b4a",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "$$\n",
    "LCB(x) = \\mu(x) - \\beta \\sigma (x)\n",
    "$$\n",
    "\n",
    "β is a parameter controlling the\n",
    "degree of exploration\n",
    "\n",
    "\n",
    "Maybe try Botorch? now reason to try the framework!\n",
    "\n",
    "https://botorch.org/tutorials/multi_objective_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e2399",
   "metadata": {},
   "source": [
    "has example here how to use parEGo\n",
    "\n",
    "https://github.com/shinya-ml/Multiobj-Bayes-opt\n",
    "\n",
    "Basically, MOPGI, custom class wrapper for Gpy's GPR to handle multiple outputs. Has also predict method using NSGA-II as the optimizer. Query dataset.get_observed seems to be the part where calls the optim.\n",
    "\n",
    "Then max iter loop for ParEGO, optim, fit using MOPGI, until done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a3124",
   "metadata": {},
   "source": [
    "##### steps\n",
    "\n",
    "- LHS? to generate 109 design points\n",
    "- LCB and ParEGO are acquisition fucntions.. Use NSGA-III or whatever as the optimizer.\n",
    "\n",
    "\n",
    "ParEGO\n",
    "\n",
    "1. Draw random weight vector λ\n",
    "2. Scalarize the objectives (using ASF) for the\n",
    "provided data\n",
    "3. Build GP on the scalarized objectives\n",
    "4. Maximize EI\n",
    "5. Evaluate and Repeat from step 1\n",
    "\n",
    "-- use LCB first, simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2713f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yunshengtian/DGEMO/blob/master/mobo/mobo.py\n",
    "\n",
    "# idea how Multiobjective bayesian optimization goes\n",
    "\n",
    "# if nothing else use this repo bc it should be able to do the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6823c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCB(mean, std, beta=.5):\n",
    "    return mean - beta*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8dc3fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2459848700.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    theta = theta / (np.sum(theta) + 1e-10\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/automl/SMAC3/blob/main/smac/optimizer/multi_objective/parego.py\n",
    "\n",
    "#rho = 0.05\n",
    "\n",
    "# Then we have to compute the weight\n",
    "theta = self.rng.rand(self.num_obj\n",
    "# Normalize st all theta values sum up to 1\n",
    "theta = theta / (np.sum(theta) + 1e-10\n",
    "#Weight the values\n",
    "theta_f = theta * valuereturn np.max(theta_f, axis=1) + self.rho * np.sum(theta_f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e55fe21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obj = 2\n",
    "n_var = 10\n",
    "dtlz5_2 = test_problem_builder('DTLZ5', n_of_variables=n_var, n_of_objectives=n_obj)\n",
    "bounds = np.array([[0]*n_var, [1]*n_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0ce303c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58719674, 0.74785616, 0.3923076 , 0.50269711, 0.57299468,\n",
       "        0.14246074, 0.32962119, 0.56221877, 0.8824898 , 0.60672576]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = create_samples(n_var, 109, bounds)\n",
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "92dbe533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtlz5_2.evaluate(x)\n",
    "y.objectives[:5]\n",
    "y = y.objectives\n",
    "y1 = y[:,0]\n",
    "y2 = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f2e2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = [f'x{i}' for i in range(1,11)]\n",
    "y_names = [\"f1\", \"f2\"]\n",
    "\n",
    "data = pd.DataFrame(np.hstack((x,y)), columns=x_names+y_names)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dbc8a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem = DataProblem(data=data, variable_names=x_names, objective_names=y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e561818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5),\n",
      "                         n_restarts_optimizer=1, random_state=7), GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5),\n",
      "                         n_restarts_optimizer=1, random_state=7)]\n"
     ]
    }
   ],
   "source": [
    "## params\n",
    "\n",
    "#x_bound = np.zeros(10)\n",
    "#rho = 0.\n",
    "#xi = 1.\n",
    "\n",
    "kernel = Matern(length_scale=1.0)\n",
    "\n",
    "gprs = []\n",
    "# create gprs\n",
    "for i in range(n_obj):\n",
    "    print(i)\n",
    "    gprs.append(GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y[:,i]))\n",
    "\n",
    "print(gprs)   \n",
    "    \n",
    "#gpr1 = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y1)\n",
    "#gpr2 = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "970e5e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.84357078, 0.56154479, 1.54343402, 1.45377182, 0.37747643,\n",
      "       1.06103076, 0.62867658, 0.96122758, 1.40706153, 1.85578989,\n",
      "       0.16113716, 1.59466936, 1.41569017, 0.75816532, 1.8237145 ,\n",
      "       0.77737954, 1.41165004, 1.15650311, 1.33769728, 0.42206558,\n",
      "       0.62686486, 1.09549569, 0.41348917, 0.34377553, 1.45423065,\n",
      "       1.75300867, 0.59378434, 1.03217908, 0.40779123, 0.61331172,\n",
      "       0.84789784, 1.54428969, 1.6477932 , 1.36684213, 1.84241149,\n",
      "       0.57096248, 0.92082799, 1.23277878, 1.25385817, 0.08982221,\n",
      "       1.16347288, 0.2180288 , 1.01677086, 0.04325407, 0.93064718,\n",
      "       0.3160316 , 0.15868465, 1.67906224, 1.42112184, 1.06059372,\n",
      "       1.72392075, 0.89626865, 0.18991806, 1.74025062, 0.72236028,\n",
      "       1.66065463, 1.33196702, 0.89312047, 1.59388247, 1.28672444,\n",
      "       1.44766143, 0.61362394, 1.28787974, 1.32635314, 1.3295312 ,\n",
      "       1.44067095, 1.58376724, 1.80942358, 1.87418853, 0.11941385,\n",
      "       1.4625602 , 1.59987687, 0.80600641, 1.4047618 , 0.816303  ,\n",
      "       1.72953758, 1.51013584, 1.36531046, 0.25069423, 0.70786073,\n",
      "       1.7447857 , 1.93475945, 0.41710419, 1.92966471, 0.31833839,\n",
      "       1.42505501, 1.76751265, 0.44075421, 0.61439464, 0.06146481,\n",
      "       1.84734787, 0.00494653, 1.59922535, 0.74870338, 1.73994819,\n",
      "       1.81434892, 1.24508226, 1.8887609 , 1.1596703 , 0.52760885,\n",
      "       2.03684437, 1.10402539, 1.27737378, 1.58693882, 1.86730891,\n",
      "       0.93111895, 0.55445292, 0.46870818, 1.44810027, 0.93687525,\n",
      "       1.53069948, 0.55305166, 0.62664707, 0.85502809, 1.81934949,\n",
      "       1.98269859, 1.29109875, 0.34713099, 1.01338478]), array([1.11328708, 1.79469077, 0.890919  , 0.42346489, 1.82155246,\n",
      "       1.14052275, 1.32201524, 1.13933421, 0.01087474, 0.40637166,\n",
      "       1.98315812, 0.38410071, 0.77536465, 1.41777882, 0.06464625,\n",
      "       1.39019831, 0.20996632, 0.80194115, 1.72269404, 1.40730913,\n",
      "       1.04686396, 0.73529476, 1.42388577, 1.82467056, 0.6084635 ,\n",
      "       0.09628892, 1.62184576, 1.08155982, 2.00891802, 1.41811294,\n",
      "       1.72137665, 0.5634713 , 1.30294325, 0.61467756, 0.03403034,\n",
      "       1.41489409, 1.57144809, 1.7282432 , 0.94777178, 1.96163238,\n",
      "       1.03374727, 1.89516689, 1.14625152, 1.93156267, 1.46470884,\n",
      "       2.12540219, 1.62766445, 0.66852239, 1.3462092 , 1.2958098 ,\n",
      "       0.82436907, 1.7008456 , 1.61771026, 0.12492424, 2.12526729,\n",
      "       0.81223395, 1.23137835, 1.36239903, 0.29957735, 1.61425573,\n",
      "       0.87103459, 1.33184774, 0.93143099, 1.07533349, 0.87178187,\n",
      "       0.46987727, 0.53092401, 0.92360532, 1.20988435, 1.86854476,\n",
      "       1.45164027, 0.44604273, 1.29517601, 0.79200392, 1.20932601,\n",
      "       1.06570156, 0.26305934, 0.42112016, 1.73064883, 1.39037736,\n",
      "       0.46242655, 0.26597342, 1.64584388, 0.24590112, 1.98355445,\n",
      "       1.46373136, 1.36393651, 1.87488922, 1.74886293, 1.88256773,\n",
      "       0.3645375 , 1.60143613, 0.11566534, 1.79881269, 0.77100687,\n",
      "       0.20358747, 1.73638128, 0.71402828, 1.32075467, 1.92838572,\n",
      "       0.45069491, 0.95135671, 0.67458025, 0.55730173, 0.16843263,\n",
      "       0.79196137, 1.416456  , 2.00912399, 1.42233436, 1.24228106,\n",
      "       0.56099985, 1.69503649, 1.61057196, 0.64310155, 0.44732278,\n",
      "       0.60126857, 1.02564195, 2.14528346, 1.35050316])]\n",
      "[array([0.84357078, 0.56154479, 1.54343402, 1.45377182, 0.37747643,\n",
      "       1.06103076, 0.62867658, 0.96122758, 1.40706153, 1.85578989,\n",
      "       0.16113716, 1.59466936, 1.41569017, 0.75816532, 1.8237145 ,\n",
      "       0.77737954, 1.41165004, 1.15650311, 1.33769728, 0.42206558,\n",
      "       0.62686486, 1.09549569, 0.41348917, 0.34377553, 1.45423065,\n",
      "       1.75300867, 0.59378434, 1.03217908, 0.40779123, 0.61331172,\n",
      "       0.84789784, 1.54428969, 1.6477932 , 1.36684213, 1.84241149,\n",
      "       0.57096248, 0.92082799, 1.23277878, 1.25385817, 0.08982221,\n",
      "       1.16347288, 0.2180288 , 1.01677086, 0.04325407, 0.93064718,\n",
      "       0.3160316 , 0.15868465, 1.67906224, 1.42112184, 1.06059372,\n",
      "       1.72392075, 0.89626865, 0.18991806, 1.74025062, 0.72236028,\n",
      "       1.66065463, 1.33196702, 0.89312047, 1.59388247, 1.28672444,\n",
      "       1.44766143, 0.61362394, 1.28787974, 1.32635314, 1.3295312 ,\n",
      "       1.44067095, 1.58376724, 1.80942358, 1.87418853, 0.11941385,\n",
      "       1.4625602 , 1.59987687, 0.80600641, 1.4047618 , 0.816303  ,\n",
      "       1.72953758, 1.51013584, 1.36531046, 0.25069423, 0.70786073,\n",
      "       1.7447857 , 1.93475945, 0.41710419, 1.92966471, 0.31833839,\n",
      "       1.42505501, 1.76751265, 0.44075421, 0.61439464, 0.06146481,\n",
      "       1.84734787, 0.00494653, 1.59922535, 0.74870338, 1.73994819,\n",
      "       1.81434892, 1.24508226, 1.8887609 , 1.1596703 , 0.52760885,\n",
      "       2.03684437, 1.10402539, 1.27737378, 1.58693882, 1.86730891,\n",
      "       0.93111895, 0.55445292, 0.46870818, 1.44810027, 0.93687525,\n",
      "       1.53069948, 0.55305166, 0.62664707, 0.85502809, 1.81934949,\n",
      "       1.98269859, 1.29109875, 0.34713099, 1.01338478, 1.21922594,\n",
      "       1.40270513, 0.76291587, 0.1744795 , 1.62588721, 1.6628576 ,\n",
      "       0.56039843, 0.60926428, 0.90099508, 1.96561489]), array([1.11328708, 1.79469077, 0.890919  , 0.42346489, 1.82155246,\n",
      "       1.14052275, 1.32201524, 1.13933421, 0.01087474, 0.40637166,\n",
      "       1.98315812, 0.38410071, 0.77536465, 1.41777882, 0.06464625,\n",
      "       1.39019831, 0.20996632, 0.80194115, 1.72269404, 1.40730913,\n",
      "       1.04686396, 0.73529476, 1.42388577, 1.82467056, 0.6084635 ,\n",
      "       0.09628892, 1.62184576, 1.08155982, 2.00891802, 1.41811294,\n",
      "       1.72137665, 0.5634713 , 1.30294325, 0.61467756, 0.03403034,\n",
      "       1.41489409, 1.57144809, 1.7282432 , 0.94777178, 1.96163238,\n",
      "       1.03374727, 1.89516689, 1.14625152, 1.93156267, 1.46470884,\n",
      "       2.12540219, 1.62766445, 0.66852239, 1.3462092 , 1.2958098 ,\n",
      "       0.82436907, 1.7008456 , 1.61771026, 0.12492424, 2.12526729,\n",
      "       0.81223395, 1.23137835, 1.36239903, 0.29957735, 1.61425573,\n",
      "       0.87103459, 1.33184774, 0.93143099, 1.07533349, 0.87178187,\n",
      "       0.46987727, 0.53092401, 0.92360532, 1.20988435, 1.86854476,\n",
      "       1.45164027, 0.44604273, 1.29517601, 0.79200392, 1.20932601,\n",
      "       1.06570156, 0.26305934, 0.42112016, 1.73064883, 1.39037736,\n",
      "       0.46242655, 0.26597342, 1.64584388, 0.24590112, 1.98355445,\n",
      "       1.46373136, 1.36393651, 1.87488922, 1.74886293, 1.88256773,\n",
      "       0.3645375 , 1.60143613, 0.11566534, 1.79881269, 0.77100687,\n",
      "       0.20358747, 1.73638128, 0.71402828, 1.32075467, 1.92838572,\n",
      "       0.45069491, 0.95135671, 0.67458025, 0.55730173, 0.16843263,\n",
      "       0.79196137, 1.416456  , 2.00912399, 1.42233436, 1.24228106,\n",
      "       0.56099985, 1.69503649, 1.61057196, 0.64310155, 0.44732278,\n",
      "       0.60126857, 1.02564195, 2.14528346, 1.35050316, 0.9230851 ,\n",
      "       0.89919875, 1.058346  , 1.74851308, 0.56894216, 0.47612877,\n",
      "       1.89900677, 1.6453287 , 1.04724786, 0.26831685])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(2):\n",
    "    # predict with surrogates\n",
    "    y_preds = []\n",
    "    stds = []\n",
    "    \n",
    "    # create 10 new samples ?\n",
    "    x = np.vstack((x, create_samples(n_var, 10, bounds)))\n",
    "    \n",
    "    for gpr in gprs:\n",
    "        y1_pred, std = gpr.predict(x, return_std=True)\n",
    "        y_preds.append(y1_pred)\n",
    "        stds.append(std)\n",
    "    #y2_pred, std2 = gpr2.predict(x, return_std=True) \n",
    "    \n",
    "    # ypreds and std now have n_obj amount of np.arrays. To get one just use: y_preds[0] eg for first one.\n",
    "    print(y_preds)\n",
    "    \n",
    "    # calc LCB\n",
    "    #y1_lcb = LCB(y1_pred, std1)\n",
    "    #y2_lcb = LCB(y2_pred, std2)\n",
    "    \n",
    "    #y1_idx = np.argmin(y1_lcb)\n",
    "    #y2_idx = np.argmin(y2_lcb)\n",
    "\n",
    "    # add to data ?\n",
    "    #x = np.append(x, [y1_idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acbf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6d42e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParEGO():\n",
    "    \"\"\"\n",
    "    This class keep attributes and method about ParEGO\n",
    "    Attributes\n",
    "    ----------\n",
    "    x_bounds : list\n",
    "        input domain which is optimized.\n",
    "    x_train : numpy.array\n",
    "        observed input data\n",
    "    y_train : numpy.array\n",
    "        observed output data\n",
    "    rho : float\n",
    "        hyper parameter in chebyshev scalarization\n",
    "    xi : float\n",
    "        hyper parameter in Expected Improvement\n",
    "    \"\"\"\n",
    "    def __init__(self, x_bounds, x_train, y_train, rho, xi):\n",
    "        self.x_bounds = x_bounds\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.rho = rho\n",
    "        self.xi = xi\n",
    "        self.task_num = y_train.shape[1]\n",
    "        self.train_num = y_train.shape[0]\n",
    "        self.f_theta = np.zeros(self.train_num)\n",
    "    def calc_parego(self):\n",
    "        \"\"\"\n",
    "        get the result of optimized ParEGO\n",
    "        \"\"\"\n",
    "        self.scalarization()\n",
    "        # res = minimize(self.EI, bounds=self.x_bounds, algomethod=1)\n",
    "        res = self.EI()\n",
    "        return res\n",
    "    def scalarization(self):\n",
    "        \"\"\"\n",
    "        scalarize observed output data\n",
    "        \"\"\"\n",
    "\n",
    "        theta = np.random.random_sample((self.task_num))\n",
    "\n",
    "        sum_theta = np.sum(theta)\n",
    "        theta = theta / sum_theta\n",
    "        \n",
    "        theta_f = theta * self.y_train\n",
    "        max_k = np.max(theta_f, axis = 1)\n",
    "        rho_sum_theta_f = self.rho * np.sum(theta_f, axis = 1)\n",
    "        self.f_theta = max_k + rho_sum_theta_f\n",
    "    def obj(self, x):\n",
    "        if np.any(np.all(self.x_train == x, axis=1)):\n",
    "            return 1.0e5\n",
    "        else:\n",
    "            mean, var = self.model.predict(np.atleast_2d(x))\n",
    "            std = np.sqrt(var[0,0])\n",
    "\n",
    "            # mean_inv = (-1) * mean\n",
    "            current_max = self.f_theta.max()\n",
    "            # print(current_max)\n",
    "            Z = (current_max - mean[0,0] - self.xi) / std\n",
    "            # print(norm.cdf(Z))\n",
    "            # print(norm.pdf(Z))\n",
    "            ei = (-1) * (Z * std) * norm.cdf(Z) + std * norm.pdf(Z)\n",
    "            # print(ei)\n",
    "            return ei\n",
    "    def EI(self):\n",
    "        \"\"\"\n",
    "        construct a GP model for scalarized output data\n",
    "        applying EI for this model\n",
    "        \"\"\"\n",
    "        kernel = GPy.kern.RBF(self.x_train.shape[1])\n",
    "        self.model = GPy.models.GPRegression(self.x_train, self.f_theta[:,None],kernel=kernel, normalizer=None)\n",
    "        self.model['.*Gaussian_noise.variance'].constrain_fixed(1.0e-2)\n",
    "        self.model['.*rbf.variance'].constrain_fixed(1.0)\n",
    "\n",
    "        x_dist = distance.cdist(self.x_train, self.x_train)\n",
    "        median = np.median(x_dist)\n",
    "        if median == 0:\n",
    "            lower = 1.0e-3\n",
    "            upper = 100\n",
    "        else:\n",
    "            lower = 1.0e-3 * median\n",
    "            upper = 100  * median\n",
    "        self.model['.*rbf.lengthscale'].constrain_bounded(lower, upper)\n",
    "        self.model.optimize_restarts()\n",
    "\n",
    "        array_bounds = np.array(self.x_bounds)\n",
    "        max_bound = np.argmax(array_bounds[:,0] - array_bounds[:,1])\n",
    "        terminate_vol = (0.1 ** self.x_train.shape[1]) / (array_bounds[max_bound, 1] - array_bounds[max_bound, 0])\n",
    "        res = minimize(self.obj, bounds = self.x_bounds, algmethod=1,volper = terminate_vol)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b23e359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.560775</td>\n",
       "      <td>0.124008</td>\n",
       "      <td>0.308101</td>\n",
       "      <td>0.398957</td>\n",
       "      <td>0.725020</td>\n",
       "      <td>0.639573</td>\n",
       "      <td>0.283232</td>\n",
       "      <td>0.424593</td>\n",
       "      <td>0.467520</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>1.063341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423274</td>\n",
       "      <td>0.493814</td>\n",
       "      <td>0.365374</td>\n",
       "      <td>0.508758</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.289963</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.580918</td>\n",
       "      <td>1.504593</td>\n",
       "      <td>1.179525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168388</td>\n",
       "      <td>0.929267</td>\n",
       "      <td>0.337976</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.636774</td>\n",
       "      <td>0.272181</td>\n",
       "      <td>0.410702</td>\n",
       "      <td>0.074885</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.608744</td>\n",
       "      <td>1.757766</td>\n",
       "      <td>0.476090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.774269</td>\n",
       "      <td>0.346813</td>\n",
       "      <td>0.877044</td>\n",
       "      <td>0.239686</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>0.934012</td>\n",
       "      <td>0.470484</td>\n",
       "      <td>0.229505</td>\n",
       "      <td>1.656624</td>\n",
       "      <td>0.020991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094010</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.864651</td>\n",
       "      <td>0.307506</td>\n",
       "      <td>0.202080</td>\n",
       "      <td>0.121143</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.829762</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.637416</td>\n",
       "      <td>1.931223</td>\n",
       "      <td>0.287277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.560775  0.124008  0.308101  0.398957  0.725020  0.639573  0.283232   \n",
       "1  0.423274  0.493814  0.365374  0.508758  0.106245  0.995189  0.289963   \n",
       "2  0.168388  0.929267  0.337976  0.094917  0.636774  0.272181  0.410702   \n",
       "3  0.008066  0.255611  0.774269  0.346813  0.877044  0.239686  0.338721   \n",
       "4  0.094010  0.908879  0.864651  0.307506  0.202080  0.121143  0.065626   \n",
       "\n",
       "         x8        x9       x10        f1        f2  \n",
       "0  0.424593  0.467520  0.242308  0.877493  1.063341  \n",
       "1  0.987092  0.046779  0.580918  1.504593  1.179525  \n",
       "2  0.074885  0.081247  0.608744  1.757766  0.476090  \n",
       "3  0.934012  0.470484  0.229505  1.656624  0.020991  \n",
       "4  0.829762  0.758206  0.637416  1.931223  0.287277  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4c0f70c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [182]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m initial_x \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mvariables\n\u001b[1;32m      8\u001b[0m initial_y \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mobjectives\n\u001b[0;32m---> 10\u001b[0m parego \u001b[38;5;241m=\u001b[39m \u001b[43mParEGO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m res \u001b[38;5;241m=\u001b[39m parego\u001b[38;5;241m.\u001b[39mcal_parego()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----result of DIRECT-----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [179]\u001b[0m, in \u001b[0;36mParEGO.__init__\u001b[0;34m(self, x_bounds, x_train, y_train, rho, xi)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho \u001b[38;5;241m=\u001b[39m rho\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxi \u001b[38;5;241m=\u001b[39m xi\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_num \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_num \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_num)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from desdeo_problem.surrogatemodels import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "#problem.train(GaussianProcessRegressor, {\"kernel\": Matern(1.0)}) # train will do the fit with x, and y.\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    #res = parego.cal_parego()\n",
    "    \n",
    "    print('-----result of DIRECT-----')\n",
    "    print(res)\n",
    "    \n",
    "    initial_x = np.append(initial_x, [res.x], axis=0)\n",
    "    # get next y\n",
    "    next_y = 0\n",
    "    initial_y = np.append(initial_y, [next_y], axis=0)\n",
    "    \n",
    "    data = pd.DataFrame(np.hstack((initial_x,initial_y.objectives)), columns=x_names+y_names)\n",
    "    problem = DataProblem(data=data, variable_names=x_names, objective_names=y_names)\n",
    "    problem.train(GaussianProcessRegressor, {\"kernel\": Matern(1.0)}) # train again with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff53f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "416b4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## desdeo example\n",
    "\n",
    "from desdeo_problem.surrogatemodels import GaussianProcessRegressor\n",
    "\n",
    "problem.train(GaussianProcessRegressor, {\"kernel\": Matern(nu=3/2)})\n",
    "\n",
    "evolver_G_opt = NSGAIII(problem, use_surrogates=True, selection_type=\"optimistic\")\n",
    "while evolver_G_opt.continue_evolution():\n",
    "    evolver_G_opt.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20d396fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b26e93940>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "front_G_opt = evolver_G_opt.population.objectives - evolver_G_opt.population.uncertainity\n",
    "\n",
    "\n",
    "G_opt = plt.scatter(x=front_G_opt[:,0], y=front_G_opt[:,1], label=\"Optimistic Kriging\")\n",
    "\n",
    "plt.title(f\"Fronts obtained with various algorithms on the {problem_name} problem\")\n",
    "plt.xlabel(\"F1\")\n",
    "plt.ylabel(\"F2\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38datademos_env",
   "language": "python",
   "name": "38datademos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
