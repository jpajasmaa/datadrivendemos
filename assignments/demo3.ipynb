{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357964b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbe4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c850693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from desdeo_emo.EAs import RVEA, NSGAIII\n",
    "from desdeo_problem.testproblems.TestProblems import test_problem_builder\n",
    "from desdeo_problem import DataProblem\n",
    "from desdeo_tools.utilities import fast_non_dominated_sort, hypervolume_indicator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from pyDOE import lhs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aef005",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "#### about acquisitio function in bayesian model management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f09ff5",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    " Use EI and the mean prediction to solve any single objective benchmark problem (e.g.\n",
    "Ackley, Rosenblock, sphere etc.) with any single objective optimizer (preferably GA). \n",
    "\n",
    "Set max exact function evaluations to 50 (start with 50 design points). Was the solutions\n",
    "found by EI better? (you can implement EI is you wish to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6185790e",
   "metadata": {},
   "source": [
    "##### steps\n",
    "\n",
    "voisi käyttää omaa GA, giomaran kurssilta. Siellä varmaan ratkaistu myös jokin single obj ongelma, täys pohja sieltä siihen. EI ja mean prediction ovat sitten se optimizer functio vaii?\n",
    "\n",
    "max evals 50 ja 50 individuaalia..\n",
    "\n",
    "mitä on mean prediction tässä tilanteessa? vai kuitenkin käytössä GRP ja GA on vaan optimizer? --  posterior predicted mean from Kriging surrogates <-- tässä varmaan mean prediction\n",
    "\n",
    "Voisi eka ratkaista jollain helpolla ja sitten vähän vaikeemmalla kuten tuo hartmann jossa 6 lokaalia min ja 1 global ja 6 dims on x.\n",
    "\n",
    "DOE meaning: \n",
    "\n",
    "In its simplest form, an experiment aims at predicting the outcome by introducing a change of the preconditions, which is represented by one or more independent variables, also referred to as \"input variables\" or \"predictor variables.\" The change in one or more independent variables is generally hypothesized to result in a change in one or more dependent variables, also referred to as \"output variables\" or \"response variables.\" \n",
    "\n",
    "Tämä slide:\n",
    "\n",
    "\n",
    "Muistetaans nyt pääpointti. Meillä ei ole oikeita objektive funtioita käytössä tai liian kalliita. GRP sun muut on se kevyempi objektivefunctio. GA edelleen optimoija. data on populaation jäsenet decision space. laskettuna surrogatella GPR ne on surrogate objective space. Ja oikeilla sitten oikea objective space.\n",
    "\n",
    "Oliko mean prediction error nyt sitten miten tämä mean prediction (surrogate) eroaa oikeasta mean ?\n",
    "\n",
    "Easiest Approach (single objective)\n",
    "\n",
    "- 1. Build surrogates with initial data (or DOE)\n",
    "- 2. Optimize considering the mean prediction as objectives\n",
    "- 3. Evaluate the solution with the expensive functions \n",
    "- 4. Rebuild the surrogates with the new data\n",
    "- 5. Repeat Step 2 to Step 4 until maximum number of expensive function evaluation is reached\n",
    "\n",
    "!!!! IMPORTATN !!!\n",
    "\n",
    "we need to find the sampling points by optimizing the acf.\n",
    "\n",
    "Acquicisiton functin (EI) shoudl be optimized?!\n",
    "\n",
    "\n",
    "\n",
    "I  think it was actaully ok before, atleast it was using the easy single objective style.\n",
    "\n",
    "Yea the github version is i think correct if I add optimizing the acquicisiton, be it just by sampling points or better.\n",
    "\n",
    "\n",
    "I dont get anything, now it does not work again or smh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dc5e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem is the expensive function to evaluate.\n",
    "# use ackley\n",
    "\n",
    "\n",
    "# prob takes now all as vectors, need to change GA to do so too.\n",
    "def problem(x):\n",
    "    # if only one solution to calculate\n",
    "    if x.shape[0] == 2:\n",
    "        term1 = -20 * np.exp(-0.2 * np.sqrt(0.5 * (x[0]**2 + x[1]**2)))\n",
    "        term2 = np.exp(0.5 * (np.cos(2 * np.pi * x[0]) + np.cos(2 * np.pi * x[1])))\n",
    "    else:\n",
    "        term1 = -20 * np.exp(-0.2 * np.sqrt(0.5 * (x[:,0]**2 + x[:,1]**2)))\n",
    "        term2 = np.exp(0.5 * (np.cos(2 * np.pi * x[:,0]) + np.cos(2 * np.pi * x[:,1])))\n",
    "    return term1 - term2 + np.exp(1) + 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34681512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.01342072,  6.59359908,  9.37428782])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem(np.array([[4,4],[2,2],[2,4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ccb03d",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "Now somewhat works.\n",
    "\n",
    "\n",
    "\n",
    "-- also need to try EI but should first get atleast surrogates to wrok\n",
    "\n",
    "-- run several times\n",
    "\n",
    "-- either make bounded SBX or comment about it possibly doing issues with crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "dedc61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, WhiteKernel, RationalQuadratic, DotProduct, ConstantKernel, Matern\n",
    "\n",
    "class real_GA:\n",
    "    def __init__(self, problem, pop, pop_size, pm, bounds, di, order, fitness=None, acf=False, use_surr=False, max_func_evals=50, gen_max=50):\n",
    "        self.problem = problem # problem function to solve\n",
    "        self.pop = pop # pop array to hold binary population strings\n",
    "        self.pm = pm # probability of mutation\n",
    "        self.pop_size = pop_size # population size\n",
    "        self.lbounds = bounds[0]\n",
    "        self.ubounds = bounds[1]\n",
    "        self.di = di # for crossover\n",
    "        self.order = order # for mutation\n",
    "        self.acf = acf\n",
    "        self.use_surr = use_surr\n",
    "        self.gen_max = gen_max # max generations\n",
    "        self.max_func_evals = max_func_evals\n",
    "        \n",
    "        self.best_ind = None\n",
    "        self.fitness = fitness # fitness array to hold calculated fitness values\n",
    "        self.gen = 0 # current generation\n",
    "        self.surr = None\n",
    "        \n",
    "    # start pop and evaluate each member in the pop\n",
    "    def initialize(self):\n",
    "        if len(self.pop) < 1:\n",
    "            x1range = np.random.uniform(low=self.lbounds[0], high=self.ubounds[0], size=self.pop_size)\n",
    "            x2range = np.random.uniform(low=self.lbounds[1], high=self.ubounds[1], size=self.pop_size)\n",
    "            self.pop = np.stack((x1range, x2range), axis=-1)\n",
    "\n",
    "        self.pop_size = self.pop.shape[0]\n",
    "        #self.fitness = self.evaluate(self.pop)\n",
    "        #print(self.fitness.shape)\n",
    "\n",
    "    # run the GA for one iteration\n",
    "    def run(self):\n",
    "        n = 0 # init iterations\n",
    "        self.initialize()\n",
    "\n",
    "        # while self.gen_max > n:\n",
    "        #for _ in range(1):\n",
    "        next_gen = [] # init next_gen population array\n",
    "        for i in range(int(self.pop.shape[0]/2)):\n",
    "            # select two individuals with deterministic tournament selection, append them in a next gen list for crossover\n",
    "            i1, i2 = self.tour_select()\n",
    "            s1 = self.pop[i1]\n",
    "            s2 = self.pop[i2]\n",
    "            next_gen.append(s1)\n",
    "            next_gen.append(s2)\n",
    "            \n",
    "        # crossover. Happens every time\n",
    "        next_gen = self.SBX(next_gen)\n",
    "            \n",
    "        # Mutation. happens if rand < pm for member in pop\n",
    "        for i in range(self.pop_size):\n",
    "            if np.random.rand() < self.pm:\n",
    "                next_gen[i] = self.poly_mutation(next_gen[i], self.order)\n",
    "         \n",
    "        self.pop = np.asarray(next_gen) # add next gen to self pop               \n",
    "        #self.fitness = self.evaluate(self.pop)\n",
    "        n += 1\n",
    "        self.gen += 1       \n",
    "        \n",
    "        # evaluate the best individual with real func. TODO: to use this or not?\n",
    "        self.best_ind = self.evaluate(self.pop[np.argmin(self.fitness)])\n",
    "        #self.best_ind = self.pop[np.argmin(self.fitness)]\n",
    "        #self.best_ind = np.min(self.fitness) # just put the best fitness val after opt\n",
    "        \n",
    "    \n",
    "    # evaluate population members\n",
    "    def evaluate(self, x):\n",
    "        # constraint evaluation\n",
    "        #if self.use_surr:\n",
    "        #    return self.surr.predict(x)\n",
    "        return problem(x)\n",
    "        \n",
    "        \n",
    "    # deterministic binary tournament selection\n",
    "    def tour_select(self):        \n",
    "        cf = self.fitness\n",
    "        b1 = np.argmin(cf) # get best member by fitness\n",
    "        cf = np.delete(cf, b1) # remove it from cf\n",
    "        b2 = np.argmin(cf) # get (2nd) best member by fitness\n",
    "        return b1, b2 # return best and 2nd best members as parents\n",
    "        \n",
    "        \n",
    "    # Simulated binary crossover (non-bounded)\n",
    "    def SBX(self, parents):\n",
    "        parents = np.asarray(parents)\n",
    "        pop_size, num_var = parents.shape\n",
    "        children = np.zeros_like(parents)\n",
    "        for i in range(0, pop_size, num_var):\n",
    "            p1 = (parents[i] + parents[i + 1]) / 2\n",
    "            p2 = (parents[i] - parents[i + 1]) / 2\n",
    "            beta = np.zeros(num_var)\n",
    "            alpha = np.random.rand(num_var)\n",
    "            bx = np.random.randint(0, high=2, size=num_var)\n",
    "            beta[alpha <= 0.5] = (2 * alpha[alpha <= 0.5])**(1 / (self.di + 1))\n",
    "            beta[alpha > 0.5] = (2 - 2 * alpha[alpha > 0.5])**(-1 / (self.di + 1))            \n",
    "            beta = beta * ((-1)**bx)\n",
    "            children[i] = p1 + beta * p2\n",
    "            children[i + 1] = p1 - beta * p2\n",
    "        return children\n",
    "        \n",
    "    \n",
    "    # polynomial mutation for one pop member p\n",
    "    def poly_mutation(self, p, order):\n",
    "        children = np.array([0,0])\n",
    "        for i in range(0, 2):\n",
    "            pL = self.lbounds[i]\n",
    "            pU = self.ubounds[i]\n",
    "            u = np.random.random() # r [0,1]\n",
    "            mp = 0\n",
    "            dl = (2*u)**(1/1+order) - 1\n",
    "            dr = 1 - (2*(1 - u))**(1/1+order) \n",
    "            if u <= 0.5:\n",
    "                mp = p[i] + dl*(p[i] - pL)\n",
    "            else:\n",
    "                mp = p[i] + dr*(pU - p[i])\n",
    "            children[i] = mp\n",
    "        return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b9ac2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best fitness 1.3862981070613571\n",
    "# best variable values [-0.05708943 -0.00045767]\n",
    "\n",
    "# normal GA just gets stuck on some local min anytime.\n",
    "\n",
    "# global optimum of ackley f(0,0) = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "84eb57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(dec_dim, samples, bounds):\n",
    "    # create samples \n",
    "    x = lhs(dec_dim, samples)    \n",
    "    # scale\n",
    "    lower = bounds[0]\n",
    "    upper = bounds[1]\n",
    "    x = x * (upper - lower) + lower    \n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7a53cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://modal-python.readthedocs.io/en/latest/_modules/modAL/acquisition.html#max_EI\n",
    "from scipy.stats import norm\n",
    "from scipy.special import ndtr\n",
    "\n",
    "def EI(mean, std, max_val, tradeoff):\n",
    "    z = (mean - max_val - tradeoff) / std\n",
    "    return (mean - max_val - tradeoff) * ndtr(z) + std * norm.pdf(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "6919050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "pop_s = 50\n",
    "pm = 0.1\n",
    "bounds = np.array([[-2, -2], [2, 2]]) # variable bounds (lower, upper)\n",
    "gen_max = 50\n",
    "use_surr = True\n",
    "fmax = 50 # max func evals\n",
    "di = 2 # distribution index\n",
    "order = 20 # polynomial order param\n",
    "acf = True\n",
    "\n",
    "times = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf80f62",
   "metadata": {},
   "source": [
    "### Using mean pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b62ae39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best surrogate fitness 0.14576087724346465\n",
      "best decision values [ 0.01702712 -0.03402439]\n",
      "best surr func value 7.315063331394597\n",
      "best exact func value 0.14576087724346465\n",
      "best surrogate fitness 0.14576087724346465\n",
      "best decision values [ 0.01702712 -0.03402439]\n",
      "best surr func value 7.6310960193769475\n",
      "best exact func value 0.14576087724346465\n",
      "best surrogate fitness 0.09214793786506448\n",
      "best decision values [ 2. -1.]\n",
      "best surr func value 6.808589550443987\n",
      "best exact func value 5.422131717799509\n",
      "best surrogate fitness 0.09214793786506448\n",
      "best decision values [ 0.01658697 -0.02860447]\n",
      "best surr func value 7.362969254375898\n",
      "best exact func value 0.12241565052879011\n",
      "best surrogate fitness 0.08421604940829397\n",
      "best decision values [ 0.01769091 -0.01290324]\n",
      "best surr func value 6.697486711637186\n",
      "best exact func value 0.0746589273400069\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.00093513 -0.00807396]\n",
      "best surr func value 6.583371632200098\n",
      "best exact func value 0.024747485506082967\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-2.  1.]\n",
      "best surr func value 6.79674526563114\n",
      "best exact func value 5.422131717799509\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.00019323 -0.00537266]\n",
      "best surr func value 7.525461785781141\n",
      "best exact func value 0.01597543967956483\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [ 0.00331863 -0.02282735]\n",
      "best surr func value 6.951667040522743\n",
      "best exact func value 0.07935207270297084\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [ 5.91883126e-05 -3.84360615e-03]\n",
      "best surr func value 6.854805254153854\n",
      "best exact func value 0.011266083507901925\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.0240772  -0.01961457]\n",
      "best surr func value 6.741241050759031\n",
      "best exact func value 0.11335493842296174\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.01535488 -0.00270772]\n",
      "best surr func value 6.976747576574889\n",
      "best exact func value 0.05056105544853651\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [0.04363859 0.00246833]\n",
      "best surr func value 7.000666804405364\n",
      "best exact func value 0.17370447474473139\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.04192672 -0.00630808]\n",
      "best surr func value 0.045541872158878505\n",
      "best exact func value 0.16709755583368846\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.03139175  0.00484778]\n",
      "best surr func value 7.695673681067497\n",
      "best exact func value 0.11648946599175858\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.00531077  0.00830884]\n",
      "best surr func value 7.529375092901244\n",
      "best exact func value 0.0304789945480195\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.01146392 -0.00898746]\n",
      "best surr func value 6.603189415739131\n",
      "best exact func value 0.0468439390574531\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [ 0.00034083 -0.0072352 ]\n",
      "best surr func value 7.03917436208695\n",
      "best exact func value 0.02188337589297973\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.00999675 -0.00974946]\n",
      "best surr func value 7.299470742518219\n",
      "best exact func value 0.044681013418472304\n",
      "best surrogate fitness 0.01971817500158579\n",
      "best decision values [-0.00055482  0.01071839]\n",
      "best surr func value 7.770668273291113\n",
      "best exact func value 0.033421246474510724\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "mean_pred_result_all = []\n",
    "use_EI = False\n",
    "\n",
    "x = create_samples(2, pop_s, bounds)\n",
    "pop = x\n",
    "y = problem(x)\n",
    "kernel = Matern(length_scale=1.0)\n",
    "\n",
    "model = GaussianProcessRegressor(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y)\n",
    "\n",
    "ga = real_GA(problem, pop, pop_s, pm, bounds, di, order, y, acf, use_surr, fmax, gen_max) \n",
    "\n",
    "def surrogate(model, x):\n",
    "    return model.predict(x, return_std=True)\n",
    "\n",
    "def posteori_mean_pred(x, x_samples, model):\n",
    "    # x = np.vstack((x, x_samples))\n",
    "    return model.predict(x_samples)\n",
    "    \n",
    "def expected_impr(x, x_samples, model):\n",
    "    #x = np.vstack((x, x_samples)) \n",
    "    mean, std = model.predict(x_samples, return_std=True)\n",
    "    max_val = np.max(mean)\n",
    "    tradeoff = 0.5\n",
    "\n",
    "    return EI(mean, std, max_val, tradeoff)\n",
    "    \n",
    "# .. but this is still done by creating new samples eg. random search..\n",
    "def opt_acq(x, y, model):\n",
    "    x_samples = create_samples(2, 100, bounds)\n",
    "    ix = 0\n",
    "    if use_EI:\n",
    "        scores = expected_impr(x, x_samples, model)\n",
    "        ix = np.argmax(scores)\n",
    "    else:\n",
    "        scores = posteori_mean_pred(x, x_samples, model)\n",
    "        ix = np.argmin(scores)\n",
    "    return x_samples[ix]\n",
    "\n",
    "for _ in range(times):\n",
    "    fmax = 0\n",
    "    while fmax < 50:\n",
    "        best_x = opt_acq(x, y, model)\n",
    "        \n",
    "        true_y = problem(best_x) # + 1 fmax..\n",
    "        fmax += 1\n",
    "        \n",
    "        est,  _ = surrogate(model, [best_x])\n",
    "        #print(f\"best x {best_x} estimate {est} actual {true_y}\")\n",
    "        \n",
    "        # add to data. have to keep x, y == pop.size to not break GA currently.\n",
    "        worst_y = np.argmax(y)\n",
    "        x = np.delete(x, worst_y, axis=0)\n",
    "        y = np.delete(y, worst_y, axis=0)\n",
    "    \n",
    "        x = np.vstack((x, [best_x]))\n",
    "        y = np.hstack((y, [true_y]))\n",
    "    \n",
    "        # update surr\n",
    "        model.fit(x, y)\n",
    "        \n",
    "        # no idea if this is making sense.\n",
    "        ga.pop = x\n",
    "        ga.fitness = y\n",
    "      \n",
    "        #n = 0\n",
    "        #while n < 5:\n",
    "        ga.run()\n",
    "        #n += 1\n",
    "            \n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    print(\"best surrogate fitness\", ga.fitness[fittest_idx])\n",
    "    print(\"best decision values\", ga.pop[fittest_idx])\n",
    "    print(\"best surr func value\", true_y)\n",
    "    print(\"best exact func value\", ga.best_ind)\n",
    "    \n",
    "    mean_pred_result_all.append(ga.best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9686bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14576087724346465,\n",
       " 0.14576087724346465,\n",
       " 5.422131717799509,\n",
       " 0.12241565052879011,\n",
       " 0.0746589273400069,\n",
       " 0.024747485506082967,\n",
       " 5.422131717799509,\n",
       " 0.01597543967956483,\n",
       " 0.07935207270297084,\n",
       " 0.011266083507901925,\n",
       " 0.11335493842296174,\n",
       " 0.05056105544853651,\n",
       " 0.17370447474473139,\n",
       " 0.16709755583368846,\n",
       " 0.11648946599175858,\n",
       " 0.0304789945480195,\n",
       " 0.0468439390574531,\n",
       " 0.02188337589297973,\n",
       " 0.044681013418472304,\n",
       " 0.033421246474510724]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pred_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "bf0bd7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131358454592188"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_pred_result_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df40e9",
   "metadata": {},
   "source": [
    "### using EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6ede7dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best surrogate fitness 0.2914259393094376\n",
      "best decision values [-0.0275039   0.00059213]\n",
      "best surr func value 2.6661564740626886\n",
      "best exact func value 0.09783800789134744\n",
      "best surrogate fitness 0.21082931373810965\n",
      "best decision values [-0.06574273 -0.08706948]\n",
      "best surr func value 2.6123816667001876\n",
      "best exact func value 0.6015861191869725\n",
      "best surrogate fitness 0.21082931373810965\n",
      "best decision values [ 0.02424877 -0.06084117]\n",
      "best surr func value 2.5585723721317173\n",
      "best exact func value 0.29589280134965534\n",
      "best surrogate fitness 0.07926330182462493\n",
      "best decision values [ 0.02876492 -0.04914071]\n",
      "best surr func value 1.2754966933821699\n",
      "best exact func value 0.24545689887699496\n",
      "best surrogate fitness 0.07926330182462493\n",
      "best decision values [ 0.0248384  -0.05072062]\n",
      "best surr func value 0.8537172779351785\n",
      "best exact func value 0.24274204830550516\n",
      "best surrogate fitness 0.07926330182462493\n",
      "best decision values [ 0.0187926  -0.00795301]\n",
      "best surr func value 1.6061623689036928\n",
      "best exact func value 0.06877161248799624\n",
      "best surrogate fitness 0.07926330182462493\n",
      "best decision values [0.02249904 0.01255924]\n",
      "best surr func value 6.8455244428512625\n",
      "best exact func value 0.09047723760712145\n",
      "best surrogate fitness 0.031016195041676298\n",
      "best decision values [-1.  1.]\n",
      "best surr func value 0.44239367154842313\n",
      "best exact func value 3.6253849384403622\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00684858  0.00718063]\n",
      "best surr func value 1.5977778526091164\n",
      "best exact func value 0.03068651549056156\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00698232  0.00401639]\n",
      "best surr func value 1.9273781194766073\n",
      "best exact func value 0.02451015077899754\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00681995  0.00451172]\n",
      "best surr func value 0.4034383529157495\n",
      "best exact func value 0.024908490955915852\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00702254  0.0037746 ]\n",
      "best surr func value 0.4479882380703799\n",
      "best exact func value 0.024241979308087025\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00702696  0.00436695]\n",
      "best surr func value 0.9700172534286651\n",
      "best exact func value 0.02522240755323324\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00703063  0.00659614]\n",
      "best surr func value 1.8785761826558165\n",
      "best exact func value 0.02974068093838511\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00701313  0.00241875]\n",
      "best surr func value 1.961252656565346\n",
      "best exact func value 0.022447597600752545\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00379636  0.00612086]\n",
      "best surr func value 1.883187743952103\n",
      "best exact func value 0.021752907545952382\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00370578  0.02931658]\n",
      "best surr func value 0.6154467914576074\n",
      "best exact func value 0.1066663968581878\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-6.24903998e-04 -3.08601328e-05]\n",
      "best surr func value 1.8395110609918106\n",
      "best exact func value 0.00178007319108886\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00614121  0.01307731]\n",
      "best surr func value 0.6036073827102335\n",
      "best exact func value 0.04641344758645971\n",
      "best surrogate fitness 0.024323721963401823\n",
      "best decision values [-0.00675498  0.00031573]\n",
      "best surr func value 0.47076648424602396\n",
      "best exact func value 0.02034406741696415\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "EI_result_all = []\n",
    "\n",
    "use_EI = True\n",
    "\n",
    "x = create_samples(2, pop_s, bounds)\n",
    "pop = x\n",
    "y = problem(x)\n",
    "kernel = Matern(length_scale=1.0)\n",
    "\n",
    "model = GaussianProcessRegressor(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y)\n",
    "\n",
    "ga = real_GA(problem, pop, pop_s, pm, bounds, di, order, y, acf, use_surr, fmax, gen_max) \n",
    "\n",
    "def surrogate(model, x):\n",
    "    return model.predict(x, return_std=True)\n",
    "\n",
    "def posteori_mean_pred(x, x_samples, model):\n",
    "    # x = np.vstack((x, x_samples))\n",
    "    return model.predict(x_samples)\n",
    "    \n",
    "def expected_impr(x, x_samples, model):\n",
    "    #x = np.vstack((x, x_samples)) \n",
    "    mean, std = model.predict(x_samples, return_std=True)\n",
    "    max_val = np.max(mean)\n",
    "    tradeoff = .7\n",
    "\n",
    "    return EI(mean, std, max_val, tradeoff)\n",
    "    \n",
    "# .. but this is still done by creating new samples eg. random search..\n",
    "def opt_acq(x, y, model):\n",
    "    x_samples = create_samples(2, 100, bounds)\n",
    "    ix = 0\n",
    "    if use_EI:\n",
    "        scores = expected_impr(x, x_samples, model)\n",
    "        ix = np.argmin(scores)\n",
    "    else:\n",
    "        scores = posteori_mean_pred(x, x_samples, model)\n",
    "        ix = np.argmin(scores)\n",
    "    return x_samples[ix]\n",
    "\n",
    "for _ in range(times):\n",
    "    fmax = 0\n",
    "    while fmax < 50:\n",
    "    \n",
    "        best_x = opt_acq(x, y, model)\n",
    "        \n",
    "        true_y = problem(best_x) # + 1 fmax..\n",
    "        fmax += 1\n",
    "    \n",
    "        est,  _ = surrogate(model, [best_x])\n",
    "        #print(f\"best x {best_x} estimate {est} actual {true_y}\")\n",
    "        \n",
    "        # add to data. have to keep x, y == pop.size to not break GA currently.\n",
    "        worst_y = np.argmax(y)\n",
    "        x = np.delete(x, worst_y, axis=0)\n",
    "        y = np.delete(y, worst_y, axis=0)\n",
    "    \n",
    "        x = np.vstack((x, [best_x]))\n",
    "        y = np.hstack((y, [true_y]))\n",
    "    \n",
    "        # update surr\n",
    "        model.fit(x, y)\n",
    "        ga.pop = x\n",
    "        ga.fitness = y\n",
    "      \n",
    "        # ga runs for 1 iteration\n",
    "        ga.run()\n",
    "        \n",
    "\n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    print(\"best surrogate fitness\", ga.fitness[fittest_idx])\n",
    "    print(\"best decision values\", ga.pop[fittest_idx])\n",
    "    print(\"best surr func value\", true_y)\n",
    "    print(\"best exact func value\", ga.best_ind)\n",
    "    EI_result_all.append(ga.best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c2d63959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09783800789134744,\n",
       " 0.6015861191869725,\n",
       " 0.29589280134965534,\n",
       " 0.24545689887699496,\n",
       " 0.24274204830550516,\n",
       " 0.06877161248799624,\n",
       " 0.09047723760712145,\n",
       " 3.6253849384403622,\n",
       " 0.03068651549056156,\n",
       " 0.02451015077899754,\n",
       " 0.024908490955915852,\n",
       " 0.024241979308087025,\n",
       " 0.02522240755323324,\n",
       " 0.02974068093838511,\n",
       " 0.022447597600752545,\n",
       " 0.021752907545952382,\n",
       " 0.1066663968581878,\n",
       " 0.00178007319108886,\n",
       " 0.04641344758645971,\n",
       " 0.02034406741696415]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8ac26476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28234321896852704"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(EI_result_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef00784",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "check code for mistakes.\n",
    "\n",
    "make loops to run both algos atleast 10 times. Then can compare the results between runs.\n",
    "\n",
    "-- for now EI one seems to work very nice. mean pred not so nice always, which might be as expected.\n",
    "\n",
    "\n",
    "Was assuming EI will be better, but with several 20-run blocks there was no clear winner. Maybe due to GA implementation there is too much randomness? atleast SBX is not bounded maybe that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "09eb358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process.kernels import RBF, ExpSineSquared, WhiteKernel, RationalQuadratic, DotProduct, ConstantKernel, Matern\n",
    "\n",
    "class real_GA2:\n",
    "    def __init__(self, problem, pop, pop_size, pm, bounds, di, order, acf=False, use_surr=False, max_func_evals=50, gen_max=50):\n",
    "        self.problem = problem # problem function to solve\n",
    "        self.pop = pop # pop array to hold binary population strings\n",
    "        self.pm = pm # probability of mutation\n",
    "        self.pop_size = pop_size # population size\n",
    "        self.lbounds = bounds[0]\n",
    "        self.ubounds = bounds[1]\n",
    "        self.di = di # for crossover\n",
    "        self.order = order # for mutation\n",
    "        self.acf = acf\n",
    "        self.use_surr = use_surr\n",
    "        self.gen_max = gen_max # max generations\n",
    "        self.max_func_evals = max_func_evals\n",
    "        \n",
    "        self.func_evals = 0\n",
    "        self.best_ind = None\n",
    "        self.fitness = [] # fitness array to hold calculated fitness values\n",
    "        self.gen = 0 # current generation\n",
    "        self.surr = None\n",
    "        \n",
    "    \n",
    "    # start pop and evaluate each member in the pop\n",
    "    def initialize(self):\n",
    "        if len(self.pop) < 1:\n",
    "            x1range = np.random.uniform(low=self.lbounds[0], high=self.ubounds[0], size=self.pop_size)\n",
    "            x2range = np.random.uniform(low=self.lbounds[1], high=self.ubounds[1], size=self.pop_size)\n",
    "            self.pop = np.stack((x1range, x2range), axis=-1)\n",
    "        \n",
    "        self.fitness = np.array([self.evaluate(member) for member in self.pop]) # calculate fitness for each pop member\n",
    "        \n",
    "\n",
    "    # run the GA\n",
    "    def run(self):\n",
    "        n = 0 # init iterations\n",
    "        self.initialize()\n",
    "        \n",
    "        # 1. building the surrogates with initial data\n",
    "        if self.use_surr:\n",
    "            # kernel = Matern(length_scale_bounds=(1e-10, 1000000))\n",
    "            kernel = Matern(length_scale=1.0)\n",
    "            self.surr = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(self.pop, self.fitness)\n",
    "\n",
    "        # 2. optimize part ?\n",
    "        while self.max_func_evals > self.func_evals:\n",
    "            # evaluate the population members, using surrogates if wanted\n",
    "            if self.surr is not None:\n",
    "                best_pop = self.opt_acquicition()\n",
    "                #self.pop = np.vstack((self.pop, best_pop))                \n",
    "                # eval the solution with expesive functions\n",
    "                best_fit = self.evaluate(best_pop)\n",
    "                self.best_ind = best_fit\n",
    "                self.func_evals += 1\n",
    "                \n",
    "                # remove worst individual, append new best individual\n",
    "                # this GA needs to keep pop size the same\n",
    "                worst_y = np.argmax(self.fitness)\n",
    "                self.pop = np.delete(self.pop, worst_y, axis=0)\n",
    "                self.fitness = np.delete(self.fitness, worst_y, axis=0)\n",
    "                self.pop = np.vstack((self.pop, [best_pop]))\n",
    "                self.fitness = np.hstack((self.fitness, [best_fit]))\n",
    "                \n",
    "                self.best_ind = best_fit          \n",
    "                # rebuilt surrogates?\n",
    "                self.update_surrogates()\n",
    "            else:    \n",
    "                self.fitness = np.array([self.evaluate(member) for member in self.pop])\n",
    "            \n",
    "            for _ in range(10):\n",
    "                next_gen = [] # init next_gen population array\n",
    "                for i in range(int(self.pop.shape[0]/2)):\n",
    "                    # select two individuals with deterministic tournament selection, append them in a next gen list for crossover\n",
    "                    i1, i2 = self.tour_select()\n",
    "                    s1 = self.pop[i1]\n",
    "                    s2 = self.pop[i2]\n",
    "                    next_gen.append(s1)\n",
    "                    next_gen.append(s2)\n",
    "                    \n",
    "                # crossover. Happens every time\n",
    "                next_gen = self.SBX(next_gen)\n",
    "                    \n",
    "                # Mutation. happens if rand < pm for member in pop\n",
    "                for i in range(self.pop_size):\n",
    "                    if np.random.rand() < self.pm:\n",
    "                        next_gen[i] = self.poly_mutation(next_gen[i], self.order)\n",
    "                 \n",
    "                self.pop = np.asarray(next_gen) # add next gen to self pop \n",
    "                # should evaluate the surrogate pop in ga, otherwise no direction or?\n",
    "                self.fitness = self.surr.predict(self.pop)\n",
    "\n",
    "                self.gen += 1\n",
    "        \n",
    "        \n",
    "        # evaluate the best individual with real func. TODO: to use this or not?\n",
    "        self.best_ind = self.evaluate(self.pop[np.argmin(self.fitness)])\n",
    "        \n",
    "\n",
    "    def update_surrogates(self):\n",
    "        kernel = Matern(length_scale=1.0)\n",
    "        self.surr = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(self.pop, self.fitness)\n",
    "        #print(\"updating surr\", self.surr.score(self.pop, self.fitness))\n",
    "\n",
    "    # 2. ?\n",
    "    def opt_acquicition(self):\n",
    "        x_samples = create_samples(2, 100, bounds)\n",
    "        ix = 0        \n",
    "        if self.acf:\n",
    "            scores = expected_impr(x, x_samples, model)\n",
    "            ix = np.argmax(scores)\n",
    "        else:\n",
    "            scores = posteori_mean_pred(x, x_samples, model)\n",
    "            ix = np.argmin(scores)\n",
    "        return x_samples[ix]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate population members\n",
    "    def evaluate(self, member):\n",
    "        # constraint evaluation       \n",
    "        fitness = self.fitness_evaluation(member)\n",
    "        return fitness\n",
    "        \n",
    "    # evaluates constraint violations and updates the fitness value by chosen penalty constraint method\n",
    "    def fitness_evaluation(self, x):\n",
    "        # constraint evaluation  \n",
    "        #x, infeasible = check_constraints(x)\n",
    "        fitness = problem(x)          \n",
    "        return fitness\n",
    "        \n",
    "        \n",
    "    # deterministic binary tournament selection\n",
    "    def tour_select(self):        \n",
    "        cf = self.fitness\n",
    "        b1 = np.argmin(cf) # get best member by fitness\n",
    "        cf = np.delete(cf, b1) # remove it from cf\n",
    "        b2 = np.argmin(cf) # get (2nd) best member by fitness\n",
    "        return b1, b2 # return best and 2nd best members as parents\n",
    "        \n",
    "        \n",
    "    # Simulated binary crossover (non-bounded)\n",
    "    def SBX(self, parents):\n",
    "        parents = np.asarray(parents)\n",
    "        pop_size, num_var = parents.shape\n",
    "        children = np.zeros_like(parents)\n",
    "        for i in range(0, pop_size, num_var):\n",
    "            p1 = (parents[i] + parents[i + 1]) / 2\n",
    "            p2 = (parents[i] - parents[i + 1]) / 2\n",
    "            beta = np.zeros(num_var)\n",
    "            alpha = np.random.rand(num_var)\n",
    "            bx = np.random.randint(0, high=2, size=num_var)\n",
    "            beta[alpha <= 0.5] = (2 * alpha[alpha <= 0.5])**(1 / (self.di + 1))\n",
    "            beta[alpha > 0.5] = (2 - 2 * alpha[alpha > 0.5])**(-1 / (self.di + 1))            \n",
    "            beta = beta * ((-1)**bx)\n",
    "            children[i] = p1 + beta * p2\n",
    "            children[i + 1] = p1 - beta * p2\n",
    "        return children\n",
    "        \n",
    "    \n",
    "    # polynomial mutation for one pop member p\n",
    "    def poly_mutation(self, p, order):\n",
    "        children = np.array([0,0])\n",
    "        for i in range(0, 2):\n",
    "            pL = self.lbounds[i]\n",
    "            pU = self.ubounds[i]\n",
    "            u = np.random.random() # r [0,1]\n",
    "            mp = 0\n",
    "            dl = (2*u)**(1/1+order) - 1\n",
    "            dr = 1 - (2*(1 - u))**(1/1+order) \n",
    "            if u <= 0.5:\n",
    "                mp = p[i] + dl*(p[i] - pL)\n",
    "            else:\n",
    "                mp = p[i] + dr*(pU - p[i])\n",
    "            children[i] = mp\n",
    "        return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "07256c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "pop_s = 50\n",
    "pm = 0.1\n",
    "bounds = np.array([[-1, -1], [1, 1]]) # variable bounds (lower, upper)\n",
    "gen_max = 50\n",
    "use_surr = True\n",
    "fmax = 50 # max func evals\n",
    "di = 2 # distribution index\n",
    "order = 20 # polynomial order param\n",
    "\n",
    "times = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "47d82095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "500\n",
      "best surrogate fitness -1.8407508587627035\n",
      "best decision values [ 0.95415412 -0.61315011]\n",
      "best exact func value 4.5764226026423\n",
      "50\n",
      "500\n",
      "best surrogate fitness -2.013144214640249\n",
      "best decision values [ 1.02965539 -0.16353426]\n",
      "best exact func value 3.343388380707996\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.2683448900703631\n",
      "best decision values [ 0. -1.]\n",
      "best exact func value 2.637531092108304\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.3548156428159359\n",
      "best decision values [0.33813731 0.36167462]\n",
      "best exact func value 3.514077875471969\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.3093580334893318\n",
      "best decision values [0.37165324 0.40008007]\n",
      "best exact func value 3.732625961868429\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.2030104990877284\n",
      "best decision values [ 0.15356212 -0.64161037]\n",
      "best exact func value 3.5294643845947213\n",
      "50\n",
      "500\n",
      "best surrogate fitness -5.0102144655284064e-12\n",
      "best decision values [1.25934307 0.67518703]\n",
      "best exact func value 5.603404055733019\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.5661480992423549\n",
      "best decision values [-0.50427791  1.37085074]\n",
      "best exact func value 6.02090000979166\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.4806928104247845\n",
      "best decision values [-3.46765298 -1.78418695]\n",
      "best exact func value 10.51492615634743\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.4926100179818604\n",
      "best decision values [-0.66713196 -0.89127297]\n",
      "best exact func value 4.482597266214203\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.18418645731917463\n",
      "best decision values [0.79551441 0.        ]\n",
      "best exact func value 2.9479166174367393\n",
      "50\n",
      "500\n",
      "best surrogate fitness -2.220928237019244\n",
      "best decision values [ 1.52502582 -0.56440217]\n",
      "best exact func value 6.441685520007809\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.553424145722829\n",
      "best decision values [0.79113296 0.62099918]\n",
      "best exact func value 4.578988463270466\n",
      "50\n",
      "500\n",
      "best surrogate fitness -5.769433711431005e-12\n",
      "best decision values [-2.93700978e-04  3.34114928e-01]\n",
      "best exact func value 2.360022240901781\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.3902286181358363\n",
      "best decision values [1.36593209 4.86777208]\n",
      "best exact func value 11.930101594334648\n",
      "50\n",
      "500\n",
      "best surrogate fitness -1.6255371443069924\n",
      "best decision values [-1.75319802  0.10017405]\n",
      "best exact func value 5.6032417986893925\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.4736112595679174\n",
      "best decision values [1.22232673 0.07772513]\n",
      "best exact func value 4.203473175694331\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.005007512603610653\n",
      "best decision values [1.05816479 0.07185431]\n",
      "best exact func value 3.0025006114793946\n",
      "50\n",
      "500\n",
      "best surrogate fitness -2.089739728792779\n",
      "best decision values [-0.0218387  -1.24676904]\n",
      "best exact func value 4.294006834720502\n",
      "50\n",
      "500\n",
      "best surrogate fitness -0.9400397604175232\n",
      "best decision values [-0.64603366 -0.16730556]\n",
      "best exact func value 3.5735911387135566\n"
     ]
    }
   ],
   "source": [
    "mean_pred_result_all = []\n",
    "\n",
    "#for _ in range(times):\n",
    "acf = False # use acquicisition function EI\n",
    "pop = create_samples(2, pop_s, bounds)\n",
    "\n",
    "for _ in range(times):\n",
    "    ga = real_GA2(problem, pop, pop_s, pm, bounds, di, order, acf, use_surr, fmax, gen_max) \n",
    "    ga.run()\n",
    "    \n",
    "    print(ga.max_func_evals)\n",
    "    print(ga.gen)\n",
    "    \n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    print(\"best surrogate fitness\", ga.fitness[fittest_idx])\n",
    "    print(\"best decision values\", ga.pop[fittest_idx])\n",
    "    print(\"best exact func value\", ga.best_ind)\n",
    "    mean_pred_result_all.append(ga.best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "18928d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.5764226026423,\n",
       " 3.343388380707996,\n",
       " 2.637531092108304,\n",
       " 3.514077875471969,\n",
       " 3.732625961868429,\n",
       " 3.5294643845947213,\n",
       " 5.603404055733019,\n",
       " 6.02090000979166,\n",
       " 10.51492615634743,\n",
       " 4.482597266214203,\n",
       " 2.9479166174367393,\n",
       " 6.441685520007809,\n",
       " 4.578988463270466,\n",
       " 2.360022240901781,\n",
       " 11.930101594334648,\n",
       " 5.6032417986893925,\n",
       " 4.203473175694331,\n",
       " 3.0025006114793946,\n",
       " 4.294006834720502,\n",
       " 3.5735911387135566]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pred_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "31447194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.844543289036432"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_pred_result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bffac130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best surrogate fitness -0.8803992814406474\n",
      "best decision values [-0.50473694 -0.54247599]\n",
      "best exact func value 4.333464183163539\n",
      "best surrogate fitness -0.7693100406119839\n",
      "best decision values [-2.72600847 -1.67959931]\n",
      "best exact func value 9.25266973924587\n",
      "best surrogate fitness -0.5163255046725066\n",
      "best decision values [-0.97226183 -9.75737029]\n",
      "best exact func value 16.045884377907672\n",
      "best surrogate fitness -2.3615938320932823\n",
      "best decision values [-3.38470147  1.47682301]\n",
      "best exact func value 10.435273458797562\n",
      "best surrogate fitness -1.0854356622597834\n",
      "best decision values [-3.42867302 -0.92928939]\n",
      "best exact func value 9.615691856270324\n",
      "best surrogate fitness -0.9085487142139413\n",
      "best decision values [-1.5066849  -0.58625614]\n",
      "best exact func value 6.410591989058968\n",
      "best surrogate fitness 0.0\n",
      "best decision values [-1. -1.]\n",
      "best exact func value 3.6253849384403622\n",
      "best surrogate fitness -0.2767260011637802\n",
      "best decision values [-4.56784658e-05 -1.28170650e+00]\n",
      "best exact func value 4.540534457140193\n",
      "best surrogate fitness -0.9406081020080705\n",
      "best decision values [-2.48621386 -1.96575266]\n",
      "best exact func value 8.952718764658528\n",
      "best surrogate fitness -0.629623131381714\n",
      "best decision values [-4.18197736 -7.46339622]\n",
      "best exact func value 15.997557143885182\n",
      "best surrogate fitness 0.0\n",
      "best decision values [0. 0.]\n",
      "best exact func value 0.0\n",
      "best surrogate fitness 0.0\n",
      "best decision values [0. 1.]\n",
      "best exact func value 2.637531092108304\n",
      "best surrogate fitness -0.6975602510990531\n",
      "best decision values [-0.7893296  -0.23242272]\n",
      "best exact func value 3.7211852026515615\n",
      "best surrogate fitness 0.0\n",
      "best decision values [-1.  0.]\n",
      "best exact func value 2.637531092108304\n",
      "best surrogate fitness -1.2940172875092912\n",
      "best decision values [-1.77147045e+01  7.82491886e-03]\n",
      "best exact func value 19.609036131055856\n",
      "best surrogate fitness 0.0\n",
      "best decision values [0. 1.]\n",
      "best exact func value 2.637531092108304\n",
      "best surrogate fitness 0.0\n",
      "best decision values [ 1. -1.]\n",
      "best exact func value 3.6253849384403622\n",
      "best surrogate fitness -0.7072426998701076\n",
      "best decision values [-0.79620198 -1.11257128]\n",
      "best exact func value 4.549201445195461\n",
      "best surrogate fitness 0.0\n",
      "best decision values [0. 0.]\n",
      "best exact func value 0.0\n",
      "best surrogate fitness 0.0\n",
      "best decision values [0. 0.]\n",
      "best exact func value 0.0\n"
     ]
    }
   ],
   "source": [
    "EI_result_all = []\n",
    "\n",
    "for _ in range(times):\n",
    "    acf = True # use acquicisition function EI\n",
    "    pop = create_samples(2, pop_s, bounds)\n",
    "\n",
    "    ga = real_GA2(problem, pop, pop_s, pm, bounds, di, order, acf, use_surr, fmax, gen_max) \n",
    "    ga.run()\n",
    "    fittest_idx = np.argmin(ga.fitness)\n",
    "    print(\"best surrogate fitness\", ga.fitness[fittest_idx])\n",
    "    print(\"best decision values\", ga.pop[fittest_idx])\n",
    "    print(\"best exact func value\", ga.best_ind)\n",
    "    EI_result_all.append(ga.best_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "df3f40e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.333464183163539,\n",
       " 9.25266973924587,\n",
       " 16.045884377907672,\n",
       " 10.435273458797562,\n",
       " 9.615691856270324,\n",
       " 6.410591989058968,\n",
       " 3.6253849384403622,\n",
       " 4.540534457140193,\n",
       " 8.952718764658528,\n",
       " 15.997557143885182,\n",
       " 0.0,\n",
       " 2.637531092108304,\n",
       " 3.7211852026515615,\n",
       " 2.637531092108304,\n",
       " 19.609036131055856,\n",
       " 2.637531092108304,\n",
       " 3.6253849384403622,\n",
       " 4.549201445195461,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI_result_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "be3cb57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.431358595111817"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(EI_result_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce01bcf",
   "metadata": {},
   "source": [
    "#### Botorch stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a95d55",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Solve any benchmark problems (K=2 and 5, n=10) with ParEGO and LCB.\n",
    "Start with 109 design points. Compare the hypervolume of the solutions after 100 exact function\n",
    "evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d5b4a",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "$$\n",
    "LCB(x) = \\mu(x) - \\beta \\sigma (x)\n",
    "$$\n",
    "\n",
    "β is a parameter controlling the\n",
    "degree of exploration\n",
    "\n",
    "\n",
    "Maybe try Botorch? now reason to try the framework!\n",
    "\n",
    "https://botorch.org/tutorials/multi_objective_bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e2399",
   "metadata": {},
   "source": [
    "has example here how to use parEGo\n",
    "\n",
    "https://github.com/shinya-ml/Multiobj-Bayes-opt\n",
    "\n",
    "Basically, MOPGI, custom class wrapper for Gpy's GPR to handle multiple outputs. Has also predict method using NSGA-II as the optimizer. Query dataset.get_observed seems to be the part where calls the optim.\n",
    "\n",
    "Then max iter loop for ParEGO, optim, fit using MOPGI, until done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a3124",
   "metadata": {},
   "source": [
    "##### steps\n",
    "\n",
    "- LHS? to generate 109 design points\n",
    "- LCB and ParEGO are acquisition fucntions.. Use NSGA-III or whatever as the optimizer.\n",
    "\n",
    "\n",
    "ParEGO\n",
    "\n",
    "1. Draw random weight vector λ\n",
    "2. Scalarize the objectives (using ASF) for the\n",
    "provided data\n",
    "3. Build GP on the scalarized objectives\n",
    "4. Maximize EI\n",
    "5. Evaluate and Repeat from step 1\n",
    "\n",
    "-- use LCB first, simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2713f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yunshengtian/DGEMO/blob/master/mobo/mobo.py\n",
    "\n",
    "# idea how Multiobjective bayesian optimization goes\n",
    "\n",
    "# if nothing else use this repo bc it should be able to do the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6823c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCB(mean, std, beta=.5):\n",
    "    return mean - beta*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8dc3fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2459848700.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    theta = theta / (np.sum(theta) + 1e-10\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/automl/SMAC3/blob/main/smac/optimizer/multi_objective/parego.py\n",
    "\n",
    "#rho = 0.05\n",
    "\n",
    "# Then we have to compute the weight\n",
    "theta = self.rng.rand(self.num_obj\n",
    "# Normalize st all theta values sum up to 1\n",
    "theta = theta / (np.sum(theta) + 1e-10\n",
    "#Weight the values\n",
    "theta_f = theta * valuereturn np.max(theta_f, axis=1) + self.rho * np.sum(theta_f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e55fe21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obj = 2\n",
    "n_var = 10\n",
    "dtlz5_2 = test_problem_builder('DTLZ5', n_of_variables=n_var, n_of_objectives=n_obj)\n",
    "bounds = np.array([[0]*n_var, [1]*n_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0ce303c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58719674, 0.74785616, 0.3923076 , 0.50269711, 0.57299468,\n",
       "        0.14246074, 0.32962119, 0.56221877, 0.8824898 , 0.60672576]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = create_samples(n_var, 109, bounds)\n",
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "92dbe533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtlz5_2.evaluate(x)\n",
    "y.objectives[:5]\n",
    "y = y.objectives\n",
    "y1 = y[:,0]\n",
    "y2 = y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9f2e2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names = [f'x{i}' for i in range(1,11)]\n",
    "y_names = [\"f1\", \"f2\"]\n",
    "\n",
    "data = pd.DataFrame(np.hstack((x,y)), columns=x_names+y_names)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "dbc8a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem = DataProblem(data=data, variable_names=x_names, objective_names=y_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e561818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5),\n",
      "                         n_restarts_optimizer=1, random_state=7), GaussianProcessRegressor(kernel=Matern(length_scale=1, nu=1.5),\n",
      "                         n_restarts_optimizer=1, random_state=7)]\n"
     ]
    }
   ],
   "source": [
    "## params\n",
    "\n",
    "#x_bound = np.zeros(10)\n",
    "#rho = 0.\n",
    "#xi = 1.\n",
    "\n",
    "kernel = Matern(length_scale=1.0)\n",
    "\n",
    "gprs = []\n",
    "# create gprs\n",
    "for i in range(n_obj):\n",
    "    print(i)\n",
    "    gprs.append(GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y[:,i]))\n",
    "\n",
    "print(gprs)   \n",
    "    \n",
    "#gpr1 = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y1)\n",
    "#gpr2 = GPR(kernel,n_restarts_optimizer=1,random_state=7).fit(x, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "970e5e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.84357078, 0.56154479, 1.54343402, 1.45377182, 0.37747643,\n",
      "       1.06103076, 0.62867658, 0.96122758, 1.40706153, 1.85578989,\n",
      "       0.16113716, 1.59466936, 1.41569017, 0.75816532, 1.8237145 ,\n",
      "       0.77737954, 1.41165004, 1.15650311, 1.33769728, 0.42206558,\n",
      "       0.62686486, 1.09549569, 0.41348917, 0.34377553, 1.45423065,\n",
      "       1.75300867, 0.59378434, 1.03217908, 0.40779123, 0.61331172,\n",
      "       0.84789784, 1.54428969, 1.6477932 , 1.36684213, 1.84241149,\n",
      "       0.57096248, 0.92082799, 1.23277878, 1.25385817, 0.08982221,\n",
      "       1.16347288, 0.2180288 , 1.01677086, 0.04325407, 0.93064718,\n",
      "       0.3160316 , 0.15868465, 1.67906224, 1.42112184, 1.06059372,\n",
      "       1.72392075, 0.89626865, 0.18991806, 1.74025062, 0.72236028,\n",
      "       1.66065463, 1.33196702, 0.89312047, 1.59388247, 1.28672444,\n",
      "       1.44766143, 0.61362394, 1.28787974, 1.32635314, 1.3295312 ,\n",
      "       1.44067095, 1.58376724, 1.80942358, 1.87418853, 0.11941385,\n",
      "       1.4625602 , 1.59987687, 0.80600641, 1.4047618 , 0.816303  ,\n",
      "       1.72953758, 1.51013584, 1.36531046, 0.25069423, 0.70786073,\n",
      "       1.7447857 , 1.93475945, 0.41710419, 1.92966471, 0.31833839,\n",
      "       1.42505501, 1.76751265, 0.44075421, 0.61439464, 0.06146481,\n",
      "       1.84734787, 0.00494653, 1.59922535, 0.74870338, 1.73994819,\n",
      "       1.81434892, 1.24508226, 1.8887609 , 1.1596703 , 0.52760885,\n",
      "       2.03684437, 1.10402539, 1.27737378, 1.58693882, 1.86730891,\n",
      "       0.93111895, 0.55445292, 0.46870818, 1.44810027, 0.93687525,\n",
      "       1.53069948, 0.55305166, 0.62664707, 0.85502809, 1.81934949,\n",
      "       1.98269859, 1.29109875, 0.34713099, 1.01338478]), array([1.11328708, 1.79469077, 0.890919  , 0.42346489, 1.82155246,\n",
      "       1.14052275, 1.32201524, 1.13933421, 0.01087474, 0.40637166,\n",
      "       1.98315812, 0.38410071, 0.77536465, 1.41777882, 0.06464625,\n",
      "       1.39019831, 0.20996632, 0.80194115, 1.72269404, 1.40730913,\n",
      "       1.04686396, 0.73529476, 1.42388577, 1.82467056, 0.6084635 ,\n",
      "       0.09628892, 1.62184576, 1.08155982, 2.00891802, 1.41811294,\n",
      "       1.72137665, 0.5634713 , 1.30294325, 0.61467756, 0.03403034,\n",
      "       1.41489409, 1.57144809, 1.7282432 , 0.94777178, 1.96163238,\n",
      "       1.03374727, 1.89516689, 1.14625152, 1.93156267, 1.46470884,\n",
      "       2.12540219, 1.62766445, 0.66852239, 1.3462092 , 1.2958098 ,\n",
      "       0.82436907, 1.7008456 , 1.61771026, 0.12492424, 2.12526729,\n",
      "       0.81223395, 1.23137835, 1.36239903, 0.29957735, 1.61425573,\n",
      "       0.87103459, 1.33184774, 0.93143099, 1.07533349, 0.87178187,\n",
      "       0.46987727, 0.53092401, 0.92360532, 1.20988435, 1.86854476,\n",
      "       1.45164027, 0.44604273, 1.29517601, 0.79200392, 1.20932601,\n",
      "       1.06570156, 0.26305934, 0.42112016, 1.73064883, 1.39037736,\n",
      "       0.46242655, 0.26597342, 1.64584388, 0.24590112, 1.98355445,\n",
      "       1.46373136, 1.36393651, 1.87488922, 1.74886293, 1.88256773,\n",
      "       0.3645375 , 1.60143613, 0.11566534, 1.79881269, 0.77100687,\n",
      "       0.20358747, 1.73638128, 0.71402828, 1.32075467, 1.92838572,\n",
      "       0.45069491, 0.95135671, 0.67458025, 0.55730173, 0.16843263,\n",
      "       0.79196137, 1.416456  , 2.00912399, 1.42233436, 1.24228106,\n",
      "       0.56099985, 1.69503649, 1.61057196, 0.64310155, 0.44732278,\n",
      "       0.60126857, 1.02564195, 2.14528346, 1.35050316])]\n",
      "[array([0.84357078, 0.56154479, 1.54343402, 1.45377182, 0.37747643,\n",
      "       1.06103076, 0.62867658, 0.96122758, 1.40706153, 1.85578989,\n",
      "       0.16113716, 1.59466936, 1.41569017, 0.75816532, 1.8237145 ,\n",
      "       0.77737954, 1.41165004, 1.15650311, 1.33769728, 0.42206558,\n",
      "       0.62686486, 1.09549569, 0.41348917, 0.34377553, 1.45423065,\n",
      "       1.75300867, 0.59378434, 1.03217908, 0.40779123, 0.61331172,\n",
      "       0.84789784, 1.54428969, 1.6477932 , 1.36684213, 1.84241149,\n",
      "       0.57096248, 0.92082799, 1.23277878, 1.25385817, 0.08982221,\n",
      "       1.16347288, 0.2180288 , 1.01677086, 0.04325407, 0.93064718,\n",
      "       0.3160316 , 0.15868465, 1.67906224, 1.42112184, 1.06059372,\n",
      "       1.72392075, 0.89626865, 0.18991806, 1.74025062, 0.72236028,\n",
      "       1.66065463, 1.33196702, 0.89312047, 1.59388247, 1.28672444,\n",
      "       1.44766143, 0.61362394, 1.28787974, 1.32635314, 1.3295312 ,\n",
      "       1.44067095, 1.58376724, 1.80942358, 1.87418853, 0.11941385,\n",
      "       1.4625602 , 1.59987687, 0.80600641, 1.4047618 , 0.816303  ,\n",
      "       1.72953758, 1.51013584, 1.36531046, 0.25069423, 0.70786073,\n",
      "       1.7447857 , 1.93475945, 0.41710419, 1.92966471, 0.31833839,\n",
      "       1.42505501, 1.76751265, 0.44075421, 0.61439464, 0.06146481,\n",
      "       1.84734787, 0.00494653, 1.59922535, 0.74870338, 1.73994819,\n",
      "       1.81434892, 1.24508226, 1.8887609 , 1.1596703 , 0.52760885,\n",
      "       2.03684437, 1.10402539, 1.27737378, 1.58693882, 1.86730891,\n",
      "       0.93111895, 0.55445292, 0.46870818, 1.44810027, 0.93687525,\n",
      "       1.53069948, 0.55305166, 0.62664707, 0.85502809, 1.81934949,\n",
      "       1.98269859, 1.29109875, 0.34713099, 1.01338478, 1.21922594,\n",
      "       1.40270513, 0.76291587, 0.1744795 , 1.62588721, 1.6628576 ,\n",
      "       0.56039843, 0.60926428, 0.90099508, 1.96561489]), array([1.11328708, 1.79469077, 0.890919  , 0.42346489, 1.82155246,\n",
      "       1.14052275, 1.32201524, 1.13933421, 0.01087474, 0.40637166,\n",
      "       1.98315812, 0.38410071, 0.77536465, 1.41777882, 0.06464625,\n",
      "       1.39019831, 0.20996632, 0.80194115, 1.72269404, 1.40730913,\n",
      "       1.04686396, 0.73529476, 1.42388577, 1.82467056, 0.6084635 ,\n",
      "       0.09628892, 1.62184576, 1.08155982, 2.00891802, 1.41811294,\n",
      "       1.72137665, 0.5634713 , 1.30294325, 0.61467756, 0.03403034,\n",
      "       1.41489409, 1.57144809, 1.7282432 , 0.94777178, 1.96163238,\n",
      "       1.03374727, 1.89516689, 1.14625152, 1.93156267, 1.46470884,\n",
      "       2.12540219, 1.62766445, 0.66852239, 1.3462092 , 1.2958098 ,\n",
      "       0.82436907, 1.7008456 , 1.61771026, 0.12492424, 2.12526729,\n",
      "       0.81223395, 1.23137835, 1.36239903, 0.29957735, 1.61425573,\n",
      "       0.87103459, 1.33184774, 0.93143099, 1.07533349, 0.87178187,\n",
      "       0.46987727, 0.53092401, 0.92360532, 1.20988435, 1.86854476,\n",
      "       1.45164027, 0.44604273, 1.29517601, 0.79200392, 1.20932601,\n",
      "       1.06570156, 0.26305934, 0.42112016, 1.73064883, 1.39037736,\n",
      "       0.46242655, 0.26597342, 1.64584388, 0.24590112, 1.98355445,\n",
      "       1.46373136, 1.36393651, 1.87488922, 1.74886293, 1.88256773,\n",
      "       0.3645375 , 1.60143613, 0.11566534, 1.79881269, 0.77100687,\n",
      "       0.20358747, 1.73638128, 0.71402828, 1.32075467, 1.92838572,\n",
      "       0.45069491, 0.95135671, 0.67458025, 0.55730173, 0.16843263,\n",
      "       0.79196137, 1.416456  , 2.00912399, 1.42233436, 1.24228106,\n",
      "       0.56099985, 1.69503649, 1.61057196, 0.64310155, 0.44732278,\n",
      "       0.60126857, 1.02564195, 2.14528346, 1.35050316, 0.9230851 ,\n",
      "       0.89919875, 1.058346  , 1.74851308, 0.56894216, 0.47612877,\n",
      "       1.89900677, 1.6453287 , 1.04724786, 0.26831685])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(2):\n",
    "    # predict with surrogates\n",
    "    y_preds = []\n",
    "    stds = []\n",
    "    \n",
    "    # create 10 new samples ?\n",
    "    x = np.vstack((x, create_samples(n_var, 10, bounds)))\n",
    "    \n",
    "    for gpr in gprs:\n",
    "        y1_pred, std = gpr.predict(x, return_std=True)\n",
    "        y_preds.append(y1_pred)\n",
    "        stds.append(std)\n",
    "    #y2_pred, std2 = gpr2.predict(x, return_std=True) \n",
    "    \n",
    "    # ypreds and std now have n_obj amount of np.arrays. To get one just use: y_preds[0] eg for first one.\n",
    "    print(y_preds)\n",
    "    \n",
    "    # calc LCB\n",
    "    #y1_lcb = LCB(y1_pred, std1)\n",
    "    #y2_lcb = LCB(y2_pred, std2)\n",
    "    \n",
    "    #y1_idx = np.argmin(y1_lcb)\n",
    "    #y2_idx = np.argmin(y2_lcb)\n",
    "\n",
    "    # add to data ?\n",
    "    #x = np.append(x, [y1_idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acbf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6d42e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParEGO():\n",
    "    \"\"\"\n",
    "    This class keep attributes and method about ParEGO\n",
    "    Attributes\n",
    "    ----------\n",
    "    x_bounds : list\n",
    "        input domain which is optimized.\n",
    "    x_train : numpy.array\n",
    "        observed input data\n",
    "    y_train : numpy.array\n",
    "        observed output data\n",
    "    rho : float\n",
    "        hyper parameter in chebyshev scalarization\n",
    "    xi : float\n",
    "        hyper parameter in Expected Improvement\n",
    "    \"\"\"\n",
    "    def __init__(self, x_bounds, x_train, y_train, rho, xi):\n",
    "        self.x_bounds = x_bounds\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.rho = rho\n",
    "        self.xi = xi\n",
    "        self.task_num = y_train.shape[1]\n",
    "        self.train_num = y_train.shape[0]\n",
    "        self.f_theta = np.zeros(self.train_num)\n",
    "    def calc_parego(self):\n",
    "        \"\"\"\n",
    "        get the result of optimized ParEGO\n",
    "        \"\"\"\n",
    "        self.scalarization()\n",
    "        # res = minimize(self.EI, bounds=self.x_bounds, algomethod=1)\n",
    "        res = self.EI()\n",
    "        return res\n",
    "    def scalarization(self):\n",
    "        \"\"\"\n",
    "        scalarize observed output data\n",
    "        \"\"\"\n",
    "\n",
    "        theta = np.random.random_sample((self.task_num))\n",
    "\n",
    "        sum_theta = np.sum(theta)\n",
    "        theta = theta / sum_theta\n",
    "        \n",
    "        theta_f = theta * self.y_train\n",
    "        max_k = np.max(theta_f, axis = 1)\n",
    "        rho_sum_theta_f = self.rho * np.sum(theta_f, axis = 1)\n",
    "        self.f_theta = max_k + rho_sum_theta_f\n",
    "    def obj(self, x):\n",
    "        if np.any(np.all(self.x_train == x, axis=1)):\n",
    "            return 1.0e5\n",
    "        else:\n",
    "            mean, var = self.model.predict(np.atleast_2d(x))\n",
    "            std = np.sqrt(var[0,0])\n",
    "\n",
    "            # mean_inv = (-1) * mean\n",
    "            current_max = self.f_theta.max()\n",
    "            # print(current_max)\n",
    "            Z = (current_max - mean[0,0] - self.xi) / std\n",
    "            # print(norm.cdf(Z))\n",
    "            # print(norm.pdf(Z))\n",
    "            ei = (-1) * (Z * std) * norm.cdf(Z) + std * norm.pdf(Z)\n",
    "            # print(ei)\n",
    "            return ei\n",
    "    def EI(self):\n",
    "        \"\"\"\n",
    "        construct a GP model for scalarized output data\n",
    "        applying EI for this model\n",
    "        \"\"\"\n",
    "        kernel = GPy.kern.RBF(self.x_train.shape[1])\n",
    "        self.model = GPy.models.GPRegression(self.x_train, self.f_theta[:,None],kernel=kernel, normalizer=None)\n",
    "        self.model['.*Gaussian_noise.variance'].constrain_fixed(1.0e-2)\n",
    "        self.model['.*rbf.variance'].constrain_fixed(1.0)\n",
    "\n",
    "        x_dist = distance.cdist(self.x_train, self.x_train)\n",
    "        median = np.median(x_dist)\n",
    "        if median == 0:\n",
    "            lower = 1.0e-3\n",
    "            upper = 100\n",
    "        else:\n",
    "            lower = 1.0e-3 * median\n",
    "            upper = 100  * median\n",
    "        self.model['.*rbf.lengthscale'].constrain_bounded(lower, upper)\n",
    "        self.model.optimize_restarts()\n",
    "\n",
    "        array_bounds = np.array(self.x_bounds)\n",
    "        max_bound = np.argmax(array_bounds[:,0] - array_bounds[:,1])\n",
    "        terminate_vol = (0.1 ** self.x_train.shape[1]) / (array_bounds[max_bound, 1] - array_bounds[max_bound, 0])\n",
    "        res = minimize(self.obj, bounds = self.x_bounds, algmethod=1,volper = terminate_vol)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b23e359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.560775</td>\n",
       "      <td>0.124008</td>\n",
       "      <td>0.308101</td>\n",
       "      <td>0.398957</td>\n",
       "      <td>0.725020</td>\n",
       "      <td>0.639573</td>\n",
       "      <td>0.283232</td>\n",
       "      <td>0.424593</td>\n",
       "      <td>0.467520</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.877493</td>\n",
       "      <td>1.063341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423274</td>\n",
       "      <td>0.493814</td>\n",
       "      <td>0.365374</td>\n",
       "      <td>0.508758</td>\n",
       "      <td>0.106245</td>\n",
       "      <td>0.995189</td>\n",
       "      <td>0.289963</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>0.046779</td>\n",
       "      <td>0.580918</td>\n",
       "      <td>1.504593</td>\n",
       "      <td>1.179525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168388</td>\n",
       "      <td>0.929267</td>\n",
       "      <td>0.337976</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.636774</td>\n",
       "      <td>0.272181</td>\n",
       "      <td>0.410702</td>\n",
       "      <td>0.074885</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.608744</td>\n",
       "      <td>1.757766</td>\n",
       "      <td>0.476090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.255611</td>\n",
       "      <td>0.774269</td>\n",
       "      <td>0.346813</td>\n",
       "      <td>0.877044</td>\n",
       "      <td>0.239686</td>\n",
       "      <td>0.338721</td>\n",
       "      <td>0.934012</td>\n",
       "      <td>0.470484</td>\n",
       "      <td>0.229505</td>\n",
       "      <td>1.656624</td>\n",
       "      <td>0.020991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094010</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.864651</td>\n",
       "      <td>0.307506</td>\n",
       "      <td>0.202080</td>\n",
       "      <td>0.121143</td>\n",
       "      <td>0.065626</td>\n",
       "      <td>0.829762</td>\n",
       "      <td>0.758206</td>\n",
       "      <td>0.637416</td>\n",
       "      <td>1.931223</td>\n",
       "      <td>0.287277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.560775  0.124008  0.308101  0.398957  0.725020  0.639573  0.283232   \n",
       "1  0.423274  0.493814  0.365374  0.508758  0.106245  0.995189  0.289963   \n",
       "2  0.168388  0.929267  0.337976  0.094917  0.636774  0.272181  0.410702   \n",
       "3  0.008066  0.255611  0.774269  0.346813  0.877044  0.239686  0.338721   \n",
       "4  0.094010  0.908879  0.864651  0.307506  0.202080  0.121143  0.065626   \n",
       "\n",
       "         x8        x9       x10        f1        f2  \n",
       "0  0.424593  0.467520  0.242308  0.877493  1.063341  \n",
       "1  0.987092  0.046779  0.580918  1.504593  1.179525  \n",
       "2  0.074885  0.081247  0.608744  1.757766  0.476090  \n",
       "3  0.934012  0.470484  0.229505  1.656624  0.020991  \n",
       "4  0.829762  0.758206  0.637416  1.931223  0.287277  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4c0f70c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [182]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m initial_x \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mvariables\n\u001b[1;32m      8\u001b[0m initial_y \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mobjectives\n\u001b[0;32m---> 10\u001b[0m parego \u001b[38;5;241m=\u001b[39m \u001b[43mParEGO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m res \u001b[38;5;241m=\u001b[39m parego\u001b[38;5;241m.\u001b[39mcal_parego()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----result of DIRECT-----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [179]\u001b[0m, in \u001b[0;36mParEGO.__init__\u001b[0;34m(self, x_bounds, x_train, y_train, rho, xi)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho \u001b[38;5;241m=\u001b[39m rho\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxi \u001b[38;5;241m=\u001b[39m xi\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_num \u001b[38;5;241m=\u001b[39m \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_num \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_num)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from desdeo_problem.surrogatemodels import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "#problem.train(GaussianProcessRegressor, {\"kernel\": Matern(1.0)}) # train will do the fit with x, and y.\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    #res = parego.cal_parego()\n",
    "    \n",
    "    print('-----result of DIRECT-----')\n",
    "    print(res)\n",
    "    \n",
    "    initial_x = np.append(initial_x, [res.x], axis=0)\n",
    "    # get next y\n",
    "    next_y = 0\n",
    "    initial_y = np.append(initial_y, [next_y], axis=0)\n",
    "    \n",
    "    data = pd.DataFrame(np.hstack((initial_x,initial_y.objectives)), columns=x_names+y_names)\n",
    "    problem = DataProblem(data=data, variable_names=x_names, objective_names=y_names)\n",
    "    problem.train(GaussianProcessRegressor, {\"kernel\": Matern(1.0)}) # train again with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff53f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "416b4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## desdeo example\n",
    "\n",
    "from desdeo_problem.surrogatemodels import GaussianProcessRegressor\n",
    "\n",
    "problem.train(GaussianProcessRegressor, {\"kernel\": Matern(nu=3/2)})\n",
    "\n",
    "evolver_G_opt = NSGAIII(problem, use_surrogates=True, selection_type=\"optimistic\")\n",
    "while evolver_G_opt.continue_evolution():\n",
    "    evolver_G_opt.iterate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20d396fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b26e93940>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "front_G_opt = evolver_G_opt.population.objectives - evolver_G_opt.population.uncertainity\n",
    "\n",
    "\n",
    "G_opt = plt.scatter(x=front_G_opt[:,0], y=front_G_opt[:,1], label=\"Optimistic Kriging\")\n",
    "\n",
    "plt.title(f\"Fronts obtained with various algorithms on the {problem_name} problem\")\n",
    "plt.xlabel(\"F1\")\n",
    "plt.ylabel(\"F2\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "38datademos_env",
   "language": "python",
   "name": "38datademos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
